{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haill\\AppData\\Local\\Temp\\ipykernel_16584\\3371724973.py:12: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_question(words, word_map):\n",
    "#     enc_c = [word_map.get(word, word_map['<unk>']) for word in words]\n",
    "#     return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_reply(words, word_map):\n",
    "#     enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n",
    "#     [word_map['<end>']]\n",
    "#     return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad(words, word_map):\n",
    "#     enc_c = words + [word_map['<pad>']] * (100 - len(words))\n",
    "#     return enc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        with open('clean_data/encoded_graph.json', 'r') as file:\n",
    "            data_str = file.read().strip('\"')\n",
    "        self.pairs = [int(x) for x in data_str.split()]\n",
    "        self.bach=100\n",
    "        self.dataset_size = len(self.pairs)-self.bach\n",
    "        \n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        question = torch.LongTensor(self.pairs[i:i+self.bach])\n",
    "        reply = torch.LongTensor(self.pairs[i+1:i+self.bach+1])\n",
    "            \n",
    "        return question,reply\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input , target = train_dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size = 128, \n",
    "                                           shuffle=True, \n",
    "                                           pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(reply_input, reply_target):\n",
    "\n",
    "    def subsequent_mask(size):\n",
    "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
    "        return mask.unsqueeze(0)\n",
    "\n",
    "      # (batch_size, 1, 1, max_words)\n",
    "\n",
    "    reply_input_mask = reply_input!=0\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
    "    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data)\n",
    "    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
    "    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n",
    "\n",
    "    return reply_input_mask, reply_target_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements embeddings of the words and adds their positional encodings. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, max_len = 1020):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def create_positinal_encoding(self, max_len, d_model):\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        for pos in range(max_len):   # for each position of the word\n",
    "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "        pe = pe.unsqueeze(0)   # include the batch size\n",
    "        return pe\n",
    "        \n",
    "    def forward(self, encoded_words):\n",
    "        embedding = self.embed(encoded_words) * math.sqrt(self.d_model)\n",
    "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
    "        embedding = self.dropout(embedding)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, heads, d_model):\n",
    "\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % heads == 0\n",
    "        self.d_k = d_model // heads\n",
    "        self.heads = heads\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        self.concat = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, query, key, value, mask):\n",
    "        \"\"\"\n",
    "        query, key, value of shape: (batch_size, max_len, 512)\n",
    "        mask of shape: (batch_size, 1, 1, max_words)\n",
    "        \"\"\"\n",
    "        # (batch_size, max_len, 512)\n",
    "        query = self.query(query)\n",
    "        key = self.key(key)\n",
    "        value = self.value(value)\n",
    "\n",
    "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)\n",
    "\n",
    "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
    "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n",
    "        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n",
    "        weights = self.dropout(weights)\n",
    "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
    "        context = torch.matmul(weights, value)\n",
    "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
    "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
    "        # (batch_size, max_len, h * d_k)\n",
    "        interacted = self.concat(context)\n",
    "        return interacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, middle_dim = 2048):\n",
    "        super(FeedForward, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
    "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(self.dropout(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
    "        self.feed_forward = FeedForward(d_model)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, embeddings, mask):\n",
    "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
    "        interacted = self.layernorm(interacted + embeddings)\n",
    "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
    "        encoded = self.layernorm(feed_forward_out + interacted)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, heads, num_layers, word_map):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.vocab_size = len(word_map)\n",
    "        self.embed = Embeddings(self.vocab_size, d_model)\n",
    "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
    "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
    "        \n",
    "    def encode(self, src_words, src_mask):\n",
    "        src_embeddings = self.embed(src_words)\n",
    "        for layer in self.encoder:\n",
    "            src_embeddings = layer(src_embeddings, src_mask)\n",
    "        return src_embeddings\n",
    "        \n",
    "    def forward(self, src_words, src_mask):\n",
    "        encoded = self.encode(src_words, src_mask)\n",
    "        out = F.log_softmax(self.logit(encoded), dim = 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdamWarmup:\n",
    "    def __init__(self, model_size, warmup_steps, optimizer):\n",
    "\n",
    "        self.model_size = model_size\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.optimizer = optimizer\n",
    "        self.current_step = 0\n",
    "        self.lr = 0\n",
    "\n",
    "    def get_lr(self):\n",
    "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
    "\n",
    "    def step(self):\n",
    "        # Increment the number of steps each time we call the step function\n",
    "        self.current_step += 1\n",
    "        lr = self.get_lr()\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        # update the learning rate\n",
    "        self.lr = lr\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossWithLS(nn.Module):\n",
    "\n",
    "    def __init__(self, size, smooth):\n",
    "        super(LossWithLS, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
    "        self.confidence = 1.0 - smooth\n",
    "        self.smooth = smooth\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, prediction, target, mask):\n",
    "        \"\"\"\n",
    "        prediction of shape: (batch_size, max_words, vocab_size)\n",
    "        target and mask of shape: (batch_size, max_words)\n",
    "        \"\"\"\n",
    "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
    "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
    "        mask = mask.float()\n",
    "        mask = mask.view(-1)       # (batch_size * max_words)\n",
    "        labels = prediction.data.clone()\n",
    "        labels.fill_(self.smooth / (self.size - 1))\n",
    "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n",
    "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Workplace\\NLP\\chatbot\\env\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "d_model = 512\n",
    "heads = 8\n",
    "num_layers = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 10\n",
    "\n",
    "with open('clean_data/word_map.json', 'r') as j:\n",
    "    word_map = json.load(j)\n",
    "    \n",
    "transformer = Transformer(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map)\n",
    "transformer = transformer.to(device)\n",
    "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0005, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
    "criterion = LossWithLS(len(word_map), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20187"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter = len(train_loader)\n",
    "num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = torch.load(\"model_save/checkpoint_5.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, transformer, criterion, epoch):\n",
    "    log_path = \"tensorboard\"\n",
    "    if os.path.isdir(log_path):\n",
    "        shutil.rmtree(log_path)\n",
    "    os.mkdir(log_path)\n",
    "    writer = SummaryWriter(log_path)\n",
    "    transformer.train()\n",
    "    losses = []\n",
    "    count = 0\n",
    "\n",
    "    for i, (question,reply) in enumerate(train_loader):\n",
    "        \n",
    "        samples = question.shape[0]\n",
    "\n",
    "        # Move to device\n",
    "        question=question.to(device)\n",
    "        reply = reply.to(device)\n",
    "\n",
    "        # Prepare Target Data\n",
    "\n",
    "        # Create mask and add dimensions\n",
    "        reply_input_mask, reply_target_mask = create_masks(question, reply)\n",
    "\n",
    "        # Get the transformer outputs\n",
    "        out = transformer(question, reply_input_mask)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(out, reply, reply_target_mask)\n",
    "        transformer_optimizer.optimizer.zero_grad()\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        transformer_optimizer.step()\n",
    "        \n",
    "        loss_value = loss.item()\n",
    "        # count += samples\n",
    "        \n",
    "        # if i % 1000 == 0:\n",
    "        print(\"Epoch {}/{} | Iteration {}/{} | Loss value : {}\".format(epoch + 1 , epochs , i , num_iter, loss_value))\n",
    "        losses.append(loss_value)\n",
    "        writer.add_scalar(\"Train/Loss\" , np.mean(losses), epoch*num_iter + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Iteration 0/20187 | Loss value : 1.0963610410690308\n",
      "Epoch 1/10 | Iteration 1/20187 | Loss value : 1.0964769124984741\n",
      "Epoch 1/10 | Iteration 2/20187 | Loss value : 1.137054204940796\n",
      "Epoch 1/10 | Iteration 3/20187 | Loss value : 1.1022404432296753\n",
      "Epoch 1/10 | Iteration 4/20187 | Loss value : 1.102308750152588\n",
      "Epoch 1/10 | Iteration 5/20187 | Loss value : 1.106292724609375\n",
      "Epoch 1/10 | Iteration 6/20187 | Loss value : 1.0935697555541992\n",
      "Epoch 1/10 | Iteration 7/20187 | Loss value : 1.1028720140457153\n",
      "Epoch 1/10 | Iteration 8/20187 | Loss value : 1.1042364835739136\n",
      "Epoch 1/10 | Iteration 9/20187 | Loss value : 1.1409332752227783\n",
      "Epoch 1/10 | Iteration 10/20187 | Loss value : 1.1462090015411377\n",
      "Epoch 1/10 | Iteration 11/20187 | Loss value : 1.1002463102340698\n",
      "Epoch 1/10 | Iteration 12/20187 | Loss value : 1.1356818675994873\n",
      "Epoch 1/10 | Iteration 13/20187 | Loss value : 1.129370093345642\n",
      "Epoch 1/10 | Iteration 14/20187 | Loss value : 1.134246826171875\n",
      "Epoch 1/10 | Iteration 15/20187 | Loss value : 1.1210590600967407\n",
      "Epoch 1/10 | Iteration 16/20187 | Loss value : 1.0807528495788574\n",
      "Epoch 1/10 | Iteration 17/20187 | Loss value : 1.1360021829605103\n",
      "Epoch 1/10 | Iteration 18/20187 | Loss value : 1.0871472358703613\n",
      "Epoch 1/10 | Iteration 19/20187 | Loss value : 1.1017706394195557\n",
      "Epoch 1/10 | Iteration 20/20187 | Loss value : 1.1314274072647095\n",
      "Epoch 1/10 | Iteration 21/20187 | Loss value : 1.1327861547470093\n",
      "Epoch 1/10 | Iteration 22/20187 | Loss value : 1.1019492149353027\n",
      "Epoch 1/10 | Iteration 23/20187 | Loss value : 1.114540696144104\n",
      "Epoch 1/10 | Iteration 24/20187 | Loss value : 1.1150884628295898\n",
      "Epoch 1/10 | Iteration 25/20187 | Loss value : 1.1263920068740845\n",
      "Epoch 1/10 | Iteration 26/20187 | Loss value : 1.1369365453720093\n",
      "Epoch 1/10 | Iteration 27/20187 | Loss value : 1.1145789623260498\n",
      "Epoch 1/10 | Iteration 28/20187 | Loss value : 1.0718376636505127\n",
      "Epoch 1/10 | Iteration 29/20187 | Loss value : 1.1108099222183228\n",
      "Epoch 1/10 | Iteration 30/20187 | Loss value : 1.1079412698745728\n",
      "Epoch 1/10 | Iteration 31/20187 | Loss value : 1.086356520652771\n",
      "Epoch 1/10 | Iteration 32/20187 | Loss value : 1.0850260257720947\n",
      "Epoch 1/10 | Iteration 33/20187 | Loss value : 1.1200637817382812\n",
      "Epoch 1/10 | Iteration 34/20187 | Loss value : 1.1237092018127441\n",
      "Epoch 1/10 | Iteration 35/20187 | Loss value : 1.102226972579956\n",
      "Epoch 1/10 | Iteration 36/20187 | Loss value : 1.114066481590271\n",
      "Epoch 1/10 | Iteration 37/20187 | Loss value : 1.1291491985321045\n",
      "Epoch 1/10 | Iteration 38/20187 | Loss value : 1.115099310874939\n",
      "Epoch 1/10 | Iteration 39/20187 | Loss value : 1.0925089120864868\n",
      "Epoch 1/10 | Iteration 40/20187 | Loss value : 1.1501182317733765\n",
      "Epoch 1/10 | Iteration 41/20187 | Loss value : 1.0977582931518555\n",
      "Epoch 1/10 | Iteration 42/20187 | Loss value : 1.0899158716201782\n",
      "Epoch 1/10 | Iteration 43/20187 | Loss value : 1.1428149938583374\n",
      "Epoch 1/10 | Iteration 44/20187 | Loss value : 1.137050986289978\n",
      "Epoch 1/10 | Iteration 45/20187 | Loss value : 1.0830246210098267\n",
      "Epoch 1/10 | Iteration 46/20187 | Loss value : 1.1120991706848145\n",
      "Epoch 1/10 | Iteration 47/20187 | Loss value : 1.1323928833007812\n",
      "Epoch 1/10 | Iteration 48/20187 | Loss value : 1.1137540340423584\n",
      "Epoch 1/10 | Iteration 49/20187 | Loss value : 1.1013855934143066\n",
      "Epoch 1/10 | Iteration 50/20187 | Loss value : 1.0933969020843506\n",
      "Epoch 1/10 | Iteration 51/20187 | Loss value : 1.1254448890686035\n",
      "Epoch 1/10 | Iteration 52/20187 | Loss value : 1.1088157892227173\n",
      "Epoch 1/10 | Iteration 53/20187 | Loss value : 1.176390528678894\n",
      "Epoch 1/10 | Iteration 54/20187 | Loss value : 1.1174288988113403\n",
      "Epoch 1/10 | Iteration 55/20187 | Loss value : 1.1364589929580688\n",
      "Epoch 1/10 | Iteration 56/20187 | Loss value : 1.1218143701553345\n",
      "Epoch 1/10 | Iteration 57/20187 | Loss value : 1.0927209854125977\n",
      "Epoch 1/10 | Iteration 58/20187 | Loss value : 1.111352801322937\n",
      "Epoch 1/10 | Iteration 59/20187 | Loss value : 1.1127411127090454\n",
      "Epoch 1/10 | Iteration 60/20187 | Loss value : 1.111344575881958\n",
      "Epoch 1/10 | Iteration 61/20187 | Loss value : 1.1400253772735596\n",
      "Epoch 1/10 | Iteration 62/20187 | Loss value : 1.0883874893188477\n",
      "Epoch 1/10 | Iteration 63/20187 | Loss value : 1.1015933752059937\n",
      "Epoch 1/10 | Iteration 64/20187 | Loss value : 1.1270145177841187\n",
      "Epoch 1/10 | Iteration 65/20187 | Loss value : 1.1504615545272827\n",
      "Epoch 1/10 | Iteration 66/20187 | Loss value : 1.1131207942962646\n",
      "Epoch 1/10 | Iteration 67/20187 | Loss value : 1.1367383003234863\n",
      "Epoch 1/10 | Iteration 68/20187 | Loss value : 1.1383705139160156\n",
      "Epoch 1/10 | Iteration 69/20187 | Loss value : 1.139602780342102\n",
      "Epoch 1/10 | Iteration 70/20187 | Loss value : 1.1292270421981812\n",
      "Epoch 1/10 | Iteration 71/20187 | Loss value : 1.062434434890747\n",
      "Epoch 1/10 | Iteration 72/20187 | Loss value : 1.1064865589141846\n",
      "Epoch 1/10 | Iteration 73/20187 | Loss value : 1.1341744661331177\n",
      "Epoch 1/10 | Iteration 74/20187 | Loss value : 1.1649715900421143\n",
      "Epoch 1/10 | Iteration 75/20187 | Loss value : 1.1118639707565308\n",
      "Epoch 1/10 | Iteration 76/20187 | Loss value : 1.0959182977676392\n",
      "Epoch 1/10 | Iteration 77/20187 | Loss value : 1.0998458862304688\n",
      "Epoch 1/10 | Iteration 78/20187 | Loss value : 1.1093746423721313\n",
      "Epoch 1/10 | Iteration 79/20187 | Loss value : 1.112662672996521\n",
      "Epoch 1/10 | Iteration 80/20187 | Loss value : 1.061452865600586\n",
      "Epoch 1/10 | Iteration 81/20187 | Loss value : 1.0890312194824219\n",
      "Epoch 1/10 | Iteration 82/20187 | Loss value : 1.0775229930877686\n",
      "Epoch 1/10 | Iteration 83/20187 | Loss value : 1.1082849502563477\n",
      "Epoch 1/10 | Iteration 84/20187 | Loss value : 1.1198012828826904\n",
      "Epoch 1/10 | Iteration 85/20187 | Loss value : 1.1441935300827026\n",
      "Epoch 1/10 | Iteration 86/20187 | Loss value : 1.134372353553772\n",
      "Epoch 1/10 | Iteration 87/20187 | Loss value : 1.0953823328018188\n",
      "Epoch 1/10 | Iteration 88/20187 | Loss value : 1.112532138824463\n",
      "Epoch 1/10 | Iteration 89/20187 | Loss value : 1.1107689142227173\n",
      "Epoch 1/10 | Iteration 90/20187 | Loss value : 1.126528263092041\n",
      "Epoch 1/10 | Iteration 91/20187 | Loss value : 1.1146302223205566\n",
      "Epoch 1/10 | Iteration 92/20187 | Loss value : 1.0792409181594849\n",
      "Epoch 1/10 | Iteration 93/20187 | Loss value : 1.1157652139663696\n",
      "Epoch 1/10 | Iteration 94/20187 | Loss value : 1.1472246646881104\n",
      "Epoch 1/10 | Iteration 95/20187 | Loss value : 1.1370562314987183\n",
      "Epoch 1/10 | Iteration 96/20187 | Loss value : 1.098460078239441\n",
      "Epoch 1/10 | Iteration 97/20187 | Loss value : 1.0946743488311768\n",
      "Epoch 1/10 | Iteration 98/20187 | Loss value : 1.109915852546692\n",
      "Epoch 1/10 | Iteration 99/20187 | Loss value : 1.0973097085952759\n",
      "Epoch 1/10 | Iteration 100/20187 | Loss value : 1.0919171571731567\n",
      "Epoch 1/10 | Iteration 101/20187 | Loss value : 1.1052600145339966\n",
      "Epoch 1/10 | Iteration 102/20187 | Loss value : 1.1367733478546143\n",
      "Epoch 1/10 | Iteration 103/20187 | Loss value : 1.1375492811203003\n",
      "Epoch 1/10 | Iteration 104/20187 | Loss value : 1.0887967348098755\n",
      "Epoch 1/10 | Iteration 105/20187 | Loss value : 1.0861060619354248\n",
      "Epoch 1/10 | Iteration 106/20187 | Loss value : 1.111679196357727\n",
      "Epoch 1/10 | Iteration 107/20187 | Loss value : 1.1385078430175781\n",
      "Epoch 1/10 | Iteration 108/20187 | Loss value : 1.0697346925735474\n",
      "Epoch 1/10 | Iteration 109/20187 | Loss value : 1.1145612001419067\n",
      "Epoch 1/10 | Iteration 110/20187 | Loss value : 1.0855869054794312\n",
      "Epoch 1/10 | Iteration 111/20187 | Loss value : 1.1414121389389038\n",
      "Epoch 1/10 | Iteration 112/20187 | Loss value : 1.0928324460983276\n",
      "Epoch 1/10 | Iteration 113/20187 | Loss value : 1.0815002918243408\n",
      "Epoch 1/10 | Iteration 114/20187 | Loss value : 1.1132080554962158\n",
      "Epoch 1/10 | Iteration 115/20187 | Loss value : 1.1068572998046875\n",
      "Epoch 1/10 | Iteration 116/20187 | Loss value : 1.1080485582351685\n",
      "Epoch 1/10 | Iteration 117/20187 | Loss value : 1.0905022621154785\n",
      "Epoch 1/10 | Iteration 118/20187 | Loss value : 1.0859991312026978\n",
      "Epoch 1/10 | Iteration 119/20187 | Loss value : 1.084241509437561\n",
      "Epoch 1/10 | Iteration 120/20187 | Loss value : 1.113296389579773\n",
      "Epoch 1/10 | Iteration 121/20187 | Loss value : 1.1050727367401123\n",
      "Epoch 1/10 | Iteration 122/20187 | Loss value : 1.1414140462875366\n",
      "Epoch 1/10 | Iteration 123/20187 | Loss value : 1.1093683242797852\n",
      "Epoch 1/10 | Iteration 124/20187 | Loss value : 1.0897573232650757\n",
      "Epoch 1/10 | Iteration 125/20187 | Loss value : 1.1068187952041626\n",
      "Epoch 1/10 | Iteration 126/20187 | Loss value : 1.1285490989685059\n",
      "Epoch 1/10 | Iteration 127/20187 | Loss value : 1.095110535621643\n",
      "Epoch 1/10 | Iteration 128/20187 | Loss value : 1.139890432357788\n",
      "Epoch 1/10 | Iteration 129/20187 | Loss value : 1.0877190828323364\n",
      "Epoch 1/10 | Iteration 130/20187 | Loss value : 1.0689740180969238\n",
      "Epoch 1/10 | Iteration 131/20187 | Loss value : 1.164229154586792\n",
      "Epoch 1/10 | Iteration 132/20187 | Loss value : 1.1145931482315063\n",
      "Epoch 1/10 | Iteration 133/20187 | Loss value : 1.1647485494613647\n",
      "Epoch 1/10 | Iteration 134/20187 | Loss value : 1.089239478111267\n",
      "Epoch 1/10 | Iteration 135/20187 | Loss value : 1.1122125387191772\n",
      "Epoch 1/10 | Iteration 136/20187 | Loss value : 1.114559292793274\n",
      "Epoch 1/10 | Iteration 137/20187 | Loss value : 1.1422042846679688\n",
      "Epoch 1/10 | Iteration 138/20187 | Loss value : 1.1079131364822388\n",
      "Epoch 1/10 | Iteration 139/20187 | Loss value : 1.122985601425171\n",
      "Epoch 1/10 | Iteration 140/20187 | Loss value : 1.0982072353363037\n",
      "Epoch 1/10 | Iteration 141/20187 | Loss value : 1.1136339902877808\n",
      "Epoch 1/10 | Iteration 142/20187 | Loss value : 1.141037940979004\n",
      "Epoch 1/10 | Iteration 143/20187 | Loss value : 1.1226470470428467\n",
      "Epoch 1/10 | Iteration 144/20187 | Loss value : 1.1308417320251465\n",
      "Epoch 1/10 | Iteration 145/20187 | Loss value : 1.098711371421814\n",
      "Epoch 1/10 | Iteration 146/20187 | Loss value : 1.099518895149231\n",
      "Epoch 1/10 | Iteration 147/20187 | Loss value : 1.117437720298767\n",
      "Epoch 1/10 | Iteration 148/20187 | Loss value : 1.088117241859436\n",
      "Epoch 1/10 | Iteration 149/20187 | Loss value : 1.1135705709457397\n",
      "Epoch 1/10 | Iteration 150/20187 | Loss value : 1.1022475957870483\n",
      "Epoch 1/10 | Iteration 151/20187 | Loss value : 1.1120986938476562\n",
      "Epoch 1/10 | Iteration 152/20187 | Loss value : 1.107993721961975\n",
      "Epoch 1/10 | Iteration 153/20187 | Loss value : 1.1344845294952393\n",
      "Epoch 1/10 | Iteration 154/20187 | Loss value : 1.0966517925262451\n",
      "Epoch 1/10 | Iteration 155/20187 | Loss value : 1.1210246086120605\n",
      "Epoch 1/10 | Iteration 156/20187 | Loss value : 1.1046708822250366\n",
      "Epoch 1/10 | Iteration 157/20187 | Loss value : 1.1426379680633545\n",
      "Epoch 1/10 | Iteration 158/20187 | Loss value : 1.1245139837265015\n",
      "Epoch 1/10 | Iteration 159/20187 | Loss value : 1.1179473400115967\n",
      "Epoch 1/10 | Iteration 160/20187 | Loss value : 1.1185537576675415\n",
      "Epoch 1/10 | Iteration 161/20187 | Loss value : 1.0727412700653076\n",
      "Epoch 1/10 | Iteration 162/20187 | Loss value : 1.1336332559585571\n",
      "Epoch 1/10 | Iteration 163/20187 | Loss value : 1.0736140012741089\n",
      "Epoch 1/10 | Iteration 164/20187 | Loss value : 1.147956132888794\n",
      "Epoch 1/10 | Iteration 165/20187 | Loss value : 1.0954499244689941\n",
      "Epoch 1/10 | Iteration 166/20187 | Loss value : 1.0962934494018555\n",
      "Epoch 1/10 | Iteration 167/20187 | Loss value : 1.1430602073669434\n",
      "Epoch 1/10 | Iteration 168/20187 | Loss value : 1.1245338916778564\n",
      "Epoch 1/10 | Iteration 169/20187 | Loss value : 1.1155097484588623\n",
      "Epoch 1/10 | Iteration 170/20187 | Loss value : 1.136663556098938\n",
      "Epoch 1/10 | Iteration 171/20187 | Loss value : 1.0814414024353027\n",
      "Epoch 1/10 | Iteration 172/20187 | Loss value : 1.115964412689209\n",
      "Epoch 1/10 | Iteration 173/20187 | Loss value : 1.0902392864227295\n",
      "Epoch 1/10 | Iteration 174/20187 | Loss value : 1.0933924913406372\n",
      "Epoch 1/10 | Iteration 175/20187 | Loss value : 1.1206213235855103\n",
      "Epoch 1/10 | Iteration 176/20187 | Loss value : 1.1244128942489624\n",
      "Epoch 1/10 | Iteration 177/20187 | Loss value : 1.0997216701507568\n",
      "Epoch 1/10 | Iteration 178/20187 | Loss value : 1.111086368560791\n",
      "Epoch 1/10 | Iteration 179/20187 | Loss value : 1.0934171676635742\n",
      "Epoch 1/10 | Iteration 180/20187 | Loss value : 1.0961031913757324\n",
      "Epoch 1/10 | Iteration 181/20187 | Loss value : 1.1009700298309326\n",
      "Epoch 1/10 | Iteration 182/20187 | Loss value : 1.1001871824264526\n",
      "Epoch 1/10 | Iteration 183/20187 | Loss value : 1.1268699169158936\n",
      "Epoch 1/10 | Iteration 184/20187 | Loss value : 1.1046785116195679\n",
      "Epoch 1/10 | Iteration 185/20187 | Loss value : 1.0912517309188843\n",
      "Epoch 1/10 | Iteration 186/20187 | Loss value : 1.0802775621414185\n",
      "Epoch 1/10 | Iteration 187/20187 | Loss value : 1.077847957611084\n",
      "Epoch 1/10 | Iteration 188/20187 | Loss value : 1.1025317907333374\n",
      "Epoch 1/10 | Iteration 189/20187 | Loss value : 1.1334552764892578\n",
      "Epoch 1/10 | Iteration 190/20187 | Loss value : 1.1117022037506104\n",
      "Epoch 1/10 | Iteration 191/20187 | Loss value : 1.126878261566162\n",
      "Epoch 1/10 | Iteration 192/20187 | Loss value : 1.1384943723678589\n",
      "Epoch 1/10 | Iteration 193/20187 | Loss value : 1.1443895101547241\n",
      "Epoch 1/10 | Iteration 194/20187 | Loss value : 1.1287274360656738\n",
      "Epoch 1/10 | Iteration 195/20187 | Loss value : 1.0815109014511108\n",
      "Epoch 1/10 | Iteration 196/20187 | Loss value : 1.1052817106246948\n",
      "Epoch 1/10 | Iteration 197/20187 | Loss value : 1.107450008392334\n",
      "Epoch 1/10 | Iteration 198/20187 | Loss value : 1.111555814743042\n",
      "Epoch 1/10 | Iteration 199/20187 | Loss value : 1.1145747900009155\n",
      "Epoch 1/10 | Iteration 200/20187 | Loss value : 1.1122233867645264\n",
      "Epoch 1/10 | Iteration 201/20187 | Loss value : 1.0906929969787598\n",
      "Epoch 1/10 | Iteration 202/20187 | Loss value : 1.1641099452972412\n",
      "Epoch 1/10 | Iteration 203/20187 | Loss value : 1.109525203704834\n",
      "Epoch 1/10 | Iteration 204/20187 | Loss value : 1.1440768241882324\n",
      "Epoch 1/10 | Iteration 205/20187 | Loss value : 1.101245641708374\n",
      "Epoch 1/10 | Iteration 206/20187 | Loss value : 1.1336385011672974\n",
      "Epoch 1/10 | Iteration 207/20187 | Loss value : 1.1358513832092285\n",
      "Epoch 1/10 | Iteration 208/20187 | Loss value : 1.097468614578247\n",
      "Epoch 1/10 | Iteration 209/20187 | Loss value : 1.1041674613952637\n",
      "Epoch 1/10 | Iteration 210/20187 | Loss value : 1.1157066822052002\n",
      "Epoch 1/10 | Iteration 211/20187 | Loss value : 1.1253257989883423\n",
      "Epoch 1/10 | Iteration 212/20187 | Loss value : 1.1234140396118164\n",
      "Epoch 1/10 | Iteration 213/20187 | Loss value : 1.126237392425537\n",
      "Epoch 1/10 | Iteration 214/20187 | Loss value : 1.1376173496246338\n",
      "Epoch 1/10 | Iteration 215/20187 | Loss value : 1.0856091976165771\n",
      "Epoch 1/10 | Iteration 216/20187 | Loss value : 1.140568733215332\n",
      "Epoch 1/10 | Iteration 217/20187 | Loss value : 1.0907455682754517\n",
      "Epoch 1/10 | Iteration 218/20187 | Loss value : 1.1275802850723267\n",
      "Epoch 1/10 | Iteration 219/20187 | Loss value : 1.1102458238601685\n",
      "Epoch 1/10 | Iteration 220/20187 | Loss value : 1.1137696504592896\n",
      "Epoch 1/10 | Iteration 221/20187 | Loss value : 1.0924713611602783\n",
      "Epoch 1/10 | Iteration 222/20187 | Loss value : 1.1228991746902466\n",
      "Epoch 1/10 | Iteration 223/20187 | Loss value : 1.1191742420196533\n",
      "Epoch 1/10 | Iteration 224/20187 | Loss value : 1.110182762145996\n",
      "Epoch 1/10 | Iteration 225/20187 | Loss value : 1.119395136833191\n",
      "Epoch 1/10 | Iteration 226/20187 | Loss value : 1.1058861017227173\n",
      "Epoch 1/10 | Iteration 227/20187 | Loss value : 1.1237698793411255\n",
      "Epoch 1/10 | Iteration 228/20187 | Loss value : 1.0904861688613892\n",
      "Epoch 1/10 | Iteration 229/20187 | Loss value : 1.080818772315979\n",
      "Epoch 1/10 | Iteration 230/20187 | Loss value : 1.0991554260253906\n",
      "Epoch 1/10 | Iteration 231/20187 | Loss value : 1.080991506576538\n",
      "Epoch 1/10 | Iteration 232/20187 | Loss value : 1.1419183015823364\n",
      "Epoch 1/10 | Iteration 233/20187 | Loss value : 1.065415382385254\n",
      "Epoch 1/10 | Iteration 234/20187 | Loss value : 1.0851805210113525\n",
      "Epoch 1/10 | Iteration 235/20187 | Loss value : 1.1308014392852783\n",
      "Epoch 1/10 | Iteration 236/20187 | Loss value : 1.1216981410980225\n",
      "Epoch 1/10 | Iteration 237/20187 | Loss value : 1.117614507675171\n",
      "Epoch 1/10 | Iteration 238/20187 | Loss value : 1.1103909015655518\n",
      "Epoch 1/10 | Iteration 239/20187 | Loss value : 1.0902481079101562\n",
      "Epoch 1/10 | Iteration 240/20187 | Loss value : 1.1188279390335083\n",
      "Epoch 1/10 | Iteration 241/20187 | Loss value : 1.1135892868041992\n",
      "Epoch 1/10 | Iteration 242/20187 | Loss value : 1.0831009149551392\n",
      "Epoch 1/10 | Iteration 243/20187 | Loss value : 1.1371369361877441\n",
      "Epoch 1/10 | Iteration 244/20187 | Loss value : 1.1353787183761597\n",
      "Epoch 1/10 | Iteration 245/20187 | Loss value : 1.1162726879119873\n",
      "Epoch 1/10 | Iteration 246/20187 | Loss value : 1.1328034400939941\n",
      "Epoch 1/10 | Iteration 247/20187 | Loss value : 1.1388529539108276\n",
      "Epoch 1/10 | Iteration 248/20187 | Loss value : 1.1264615058898926\n",
      "Epoch 1/10 | Iteration 249/20187 | Loss value : 1.1123363971710205\n",
      "Epoch 1/10 | Iteration 250/20187 | Loss value : 1.1163818836212158\n",
      "Epoch 1/10 | Iteration 251/20187 | Loss value : 1.1187435388565063\n",
      "Epoch 1/10 | Iteration 252/20187 | Loss value : 1.1089729070663452\n",
      "Epoch 1/10 | Iteration 253/20187 | Loss value : 1.0948519706726074\n",
      "Epoch 1/10 | Iteration 254/20187 | Loss value : 1.098764419555664\n",
      "Epoch 1/10 | Iteration 255/20187 | Loss value : 1.1149052381515503\n",
      "Epoch 1/10 | Iteration 256/20187 | Loss value : 1.0825259685516357\n",
      "Epoch 1/10 | Iteration 257/20187 | Loss value : 1.150277853012085\n",
      "Epoch 1/10 | Iteration 258/20187 | Loss value : 1.1160919666290283\n",
      "Epoch 1/10 | Iteration 259/20187 | Loss value : 1.0872576236724854\n",
      "Epoch 1/10 | Iteration 260/20187 | Loss value : 1.14191472530365\n",
      "Epoch 1/10 | Iteration 261/20187 | Loss value : 1.1060173511505127\n",
      "Epoch 1/10 | Iteration 262/20187 | Loss value : 1.0931645631790161\n",
      "Epoch 1/10 | Iteration 263/20187 | Loss value : 1.135310173034668\n",
      "Epoch 1/10 | Iteration 264/20187 | Loss value : 1.141489028930664\n",
      "Epoch 1/10 | Iteration 265/20187 | Loss value : 1.1050746440887451\n",
      "Epoch 1/10 | Iteration 266/20187 | Loss value : 1.0999350547790527\n",
      "Epoch 1/10 | Iteration 267/20187 | Loss value : 1.147861361503601\n",
      "Epoch 1/10 | Iteration 268/20187 | Loss value : 1.0960190296173096\n",
      "Epoch 1/10 | Iteration 269/20187 | Loss value : 1.115297794342041\n",
      "Epoch 1/10 | Iteration 270/20187 | Loss value : 1.0906985998153687\n",
      "Epoch 1/10 | Iteration 271/20187 | Loss value : 1.1228049993515015\n",
      "Epoch 1/10 | Iteration 272/20187 | Loss value : 1.089525580406189\n",
      "Epoch 1/10 | Iteration 273/20187 | Loss value : 1.1289693117141724\n",
      "Epoch 1/10 | Iteration 274/20187 | Loss value : 1.1292901039123535\n",
      "Epoch 1/10 | Iteration 275/20187 | Loss value : 1.1409798860549927\n",
      "Epoch 1/10 | Iteration 276/20187 | Loss value : 1.117456316947937\n",
      "Epoch 1/10 | Iteration 277/20187 | Loss value : 1.0699824094772339\n",
      "Epoch 1/10 | Iteration 278/20187 | Loss value : 1.1125264167785645\n",
      "Epoch 1/10 | Iteration 279/20187 | Loss value : 1.0966111421585083\n",
      "Epoch 1/10 | Iteration 280/20187 | Loss value : 1.0962419509887695\n",
      "Epoch 1/10 | Iteration 281/20187 | Loss value : 1.1148322820663452\n",
      "Epoch 1/10 | Iteration 282/20187 | Loss value : 1.1139061450958252\n",
      "Epoch 1/10 | Iteration 283/20187 | Loss value : 1.0838345289230347\n",
      "Epoch 1/10 | Iteration 284/20187 | Loss value : 1.0769178867340088\n",
      "Epoch 1/10 | Iteration 285/20187 | Loss value : 1.0869375467300415\n",
      "Epoch 1/10 | Iteration 286/20187 | Loss value : 1.0960849523544312\n",
      "Epoch 1/10 | Iteration 287/20187 | Loss value : 1.1301270723342896\n",
      "Epoch 1/10 | Iteration 288/20187 | Loss value : 1.0853896141052246\n",
      "Epoch 1/10 | Iteration 289/20187 | Loss value : 1.1230698823928833\n",
      "Epoch 1/10 | Iteration 290/20187 | Loss value : 1.1203159093856812\n",
      "Epoch 1/10 | Iteration 291/20187 | Loss value : 1.0782077312469482\n",
      "Epoch 1/10 | Iteration 292/20187 | Loss value : 1.1074947118759155\n",
      "Epoch 1/10 | Iteration 293/20187 | Loss value : 1.1108760833740234\n",
      "Epoch 1/10 | Iteration 294/20187 | Loss value : 1.107334852218628\n",
      "Epoch 1/10 | Iteration 295/20187 | Loss value : 1.1287513971328735\n",
      "Epoch 1/10 | Iteration 296/20187 | Loss value : 1.087440848350525\n",
      "Epoch 1/10 | Iteration 297/20187 | Loss value : 1.1016099452972412\n",
      "Epoch 1/10 | Iteration 298/20187 | Loss value : 1.0915430784225464\n",
      "Epoch 1/10 | Iteration 299/20187 | Loss value : 1.1366921663284302\n",
      "Epoch 1/10 | Iteration 300/20187 | Loss value : 1.1290268898010254\n",
      "Epoch 1/10 | Iteration 301/20187 | Loss value : 1.1061408519744873\n",
      "Epoch 1/10 | Iteration 302/20187 | Loss value : 1.1342272758483887\n",
      "Epoch 1/10 | Iteration 303/20187 | Loss value : 1.102249026298523\n",
      "Epoch 1/10 | Iteration 304/20187 | Loss value : 1.1007752418518066\n",
      "Epoch 1/10 | Iteration 305/20187 | Loss value : 1.1277127265930176\n",
      "Epoch 1/10 | Iteration 306/20187 | Loss value : 1.1506447792053223\n",
      "Epoch 1/10 | Iteration 307/20187 | Loss value : 1.1048023700714111\n",
      "Epoch 1/10 | Iteration 308/20187 | Loss value : 1.0877004861831665\n",
      "Epoch 1/10 | Iteration 309/20187 | Loss value : 1.0790019035339355\n",
      "Epoch 1/10 | Iteration 310/20187 | Loss value : 1.1400812864303589\n",
      "Epoch 1/10 | Iteration 311/20187 | Loss value : 1.136223554611206\n",
      "Epoch 1/10 | Iteration 312/20187 | Loss value : 1.085652470588684\n",
      "Epoch 1/10 | Iteration 313/20187 | Loss value : 1.0919991731643677\n",
      "Epoch 1/10 | Iteration 314/20187 | Loss value : 1.1140942573547363\n",
      "Epoch 1/10 | Iteration 315/20187 | Loss value : 1.1366386413574219\n",
      "Epoch 1/10 | Iteration 316/20187 | Loss value : 1.0942081212997437\n",
      "Epoch 1/10 | Iteration 317/20187 | Loss value : 1.1432127952575684\n",
      "Epoch 1/10 | Iteration 318/20187 | Loss value : 1.1114661693572998\n",
      "Epoch 1/10 | Iteration 319/20187 | Loss value : 1.0968389511108398\n",
      "Epoch 1/10 | Iteration 320/20187 | Loss value : 1.0647304058074951\n",
      "Epoch 1/10 | Iteration 321/20187 | Loss value : 1.1389572620391846\n",
      "Epoch 1/10 | Iteration 322/20187 | Loss value : 1.0907429456710815\n",
      "Epoch 1/10 | Iteration 323/20187 | Loss value : 1.1108379364013672\n",
      "Epoch 1/10 | Iteration 324/20187 | Loss value : 1.149582862854004\n",
      "Epoch 1/10 | Iteration 325/20187 | Loss value : 1.1213676929473877\n",
      "Epoch 1/10 | Iteration 326/20187 | Loss value : 1.1187176704406738\n",
      "Epoch 1/10 | Iteration 327/20187 | Loss value : 1.1047390699386597\n",
      "Epoch 1/10 | Iteration 328/20187 | Loss value : 1.101151943206787\n",
      "Epoch 1/10 | Iteration 329/20187 | Loss value : 1.080384373664856\n",
      "Epoch 1/10 | Iteration 330/20187 | Loss value : 1.1020550727844238\n",
      "Epoch 1/10 | Iteration 331/20187 | Loss value : 1.1182152032852173\n",
      "Epoch 1/10 | Iteration 332/20187 | Loss value : 1.116326093673706\n",
      "Epoch 1/10 | Iteration 333/20187 | Loss value : 1.108360767364502\n",
      "Epoch 1/10 | Iteration 334/20187 | Loss value : 1.098801851272583\n",
      "Epoch 1/10 | Iteration 335/20187 | Loss value : 1.0952608585357666\n",
      "Epoch 1/10 | Iteration 336/20187 | Loss value : 1.1133828163146973\n",
      "Epoch 1/10 | Iteration 337/20187 | Loss value : 1.0883458852767944\n",
      "Epoch 1/10 | Iteration 338/20187 | Loss value : 1.0640606880187988\n",
      "Epoch 1/10 | Iteration 339/20187 | Loss value : 1.1379200220108032\n",
      "Epoch 1/10 | Iteration 340/20187 | Loss value : 1.0864958763122559\n",
      "Epoch 1/10 | Iteration 341/20187 | Loss value : 1.0932703018188477\n",
      "Epoch 1/10 | Iteration 342/20187 | Loss value : 1.1199312210083008\n",
      "Epoch 1/10 | Iteration 343/20187 | Loss value : 1.1109232902526855\n",
      "Epoch 1/10 | Iteration 344/20187 | Loss value : 1.117141842842102\n",
      "Epoch 1/10 | Iteration 345/20187 | Loss value : 1.139184594154358\n",
      "Epoch 1/10 | Iteration 346/20187 | Loss value : 1.119052529335022\n",
      "Epoch 1/10 | Iteration 347/20187 | Loss value : 1.1219162940979004\n",
      "Epoch 1/10 | Iteration 348/20187 | Loss value : 1.1368461847305298\n",
      "Epoch 1/10 | Iteration 349/20187 | Loss value : 1.088913917541504\n",
      "Epoch 1/10 | Iteration 350/20187 | Loss value : 1.1248785257339478\n",
      "Epoch 1/10 | Iteration 351/20187 | Loss value : 1.1508948802947998\n",
      "Epoch 1/10 | Iteration 352/20187 | Loss value : 1.0889886617660522\n",
      "Epoch 1/10 | Iteration 353/20187 | Loss value : 1.1290391683578491\n",
      "Epoch 1/10 | Iteration 354/20187 | Loss value : 1.0895007848739624\n",
      "Epoch 1/10 | Iteration 355/20187 | Loss value : 1.1222079992294312\n",
      "Epoch 1/10 | Iteration 356/20187 | Loss value : 1.1358108520507812\n",
      "Epoch 1/10 | Iteration 357/20187 | Loss value : 1.1200494766235352\n",
      "Epoch 1/10 | Iteration 358/20187 | Loss value : 1.0706707239151\n",
      "Epoch 1/10 | Iteration 359/20187 | Loss value : 1.125156283378601\n",
      "Epoch 1/10 | Iteration 360/20187 | Loss value : 1.1088011264801025\n",
      "Epoch 1/10 | Iteration 361/20187 | Loss value : 1.1276849508285522\n",
      "Epoch 1/10 | Iteration 362/20187 | Loss value : 1.0975327491760254\n",
      "Epoch 1/10 | Iteration 363/20187 | Loss value : 1.1052786111831665\n",
      "Epoch 1/10 | Iteration 364/20187 | Loss value : 1.119274616241455\n",
      "Epoch 1/10 | Iteration 365/20187 | Loss value : 1.1170085668563843\n",
      "Epoch 1/10 | Iteration 366/20187 | Loss value : 1.0823378562927246\n",
      "Epoch 1/10 | Iteration 367/20187 | Loss value : 1.1469662189483643\n",
      "Epoch 1/10 | Iteration 368/20187 | Loss value : 1.1085556745529175\n",
      "Epoch 1/10 | Iteration 369/20187 | Loss value : 1.080726981163025\n",
      "Epoch 1/10 | Iteration 370/20187 | Loss value : 1.1071492433547974\n",
      "Epoch 1/10 | Iteration 371/20187 | Loss value : 1.110621690750122\n",
      "Epoch 1/10 | Iteration 372/20187 | Loss value : 1.1136168241500854\n",
      "Epoch 1/10 | Iteration 373/20187 | Loss value : 1.1001228094100952\n",
      "Epoch 1/10 | Iteration 374/20187 | Loss value : 1.1050392389297485\n",
      "Epoch 1/10 | Iteration 375/20187 | Loss value : 1.0998831987380981\n",
      "Epoch 1/10 | Iteration 376/20187 | Loss value : 1.101923942565918\n",
      "Epoch 1/10 | Iteration 377/20187 | Loss value : 1.1006081104278564\n",
      "Epoch 1/10 | Iteration 378/20187 | Loss value : 1.1053696870803833\n",
      "Epoch 1/10 | Iteration 379/20187 | Loss value : 1.1220788955688477\n",
      "Epoch 1/10 | Iteration 380/20187 | Loss value : 1.1014517545700073\n",
      "Epoch 1/10 | Iteration 381/20187 | Loss value : 1.096378207206726\n",
      "Epoch 1/10 | Iteration 382/20187 | Loss value : 1.1040557622909546\n",
      "Epoch 1/10 | Iteration 383/20187 | Loss value : 1.1170200109481812\n",
      "Epoch 1/10 | Iteration 384/20187 | Loss value : 1.1474463939666748\n",
      "Epoch 1/10 | Iteration 385/20187 | Loss value : 1.1237034797668457\n",
      "Epoch 1/10 | Iteration 386/20187 | Loss value : 1.096010446548462\n",
      "Epoch 1/10 | Iteration 387/20187 | Loss value : 1.1033738851547241\n",
      "Epoch 1/10 | Iteration 388/20187 | Loss value : 1.0725566148757935\n",
      "Epoch 1/10 | Iteration 389/20187 | Loss value : 1.1215506792068481\n",
      "Epoch 1/10 | Iteration 390/20187 | Loss value : 1.1099011898040771\n",
      "Epoch 1/10 | Iteration 391/20187 | Loss value : 1.1275635957717896\n",
      "Epoch 1/10 | Iteration 392/20187 | Loss value : 1.0905773639678955\n",
      "Epoch 1/10 | Iteration 393/20187 | Loss value : 1.1402249336242676\n",
      "Epoch 1/10 | Iteration 394/20187 | Loss value : 1.0943208932876587\n",
      "Epoch 1/10 | Iteration 395/20187 | Loss value : 1.0661027431488037\n",
      "Epoch 1/10 | Iteration 396/20187 | Loss value : 1.112410068511963\n",
      "Epoch 1/10 | Iteration 397/20187 | Loss value : 1.126491665840149\n",
      "Epoch 1/10 | Iteration 398/20187 | Loss value : 1.096968173980713\n",
      "Epoch 1/10 | Iteration 399/20187 | Loss value : 1.141034722328186\n",
      "Epoch 1/10 | Iteration 400/20187 | Loss value : 1.1354693174362183\n",
      "Epoch 1/10 | Iteration 401/20187 | Loss value : 1.1141856908798218\n",
      "Epoch 1/10 | Iteration 402/20187 | Loss value : 1.1070271730422974\n",
      "Epoch 1/10 | Iteration 403/20187 | Loss value : 1.1318066120147705\n",
      "Epoch 1/10 | Iteration 404/20187 | Loss value : 1.1256608963012695\n",
      "Epoch 1/10 | Iteration 405/20187 | Loss value : 1.1056087017059326\n",
      "Epoch 1/10 | Iteration 406/20187 | Loss value : 1.1361193656921387\n",
      "Epoch 1/10 | Iteration 407/20187 | Loss value : 1.104519248008728\n",
      "Epoch 1/10 | Iteration 408/20187 | Loss value : 1.1453856229782104\n",
      "Epoch 1/10 | Iteration 409/20187 | Loss value : 1.150227665901184\n",
      "Epoch 1/10 | Iteration 410/20187 | Loss value : 1.096000075340271\n",
      "Epoch 1/10 | Iteration 411/20187 | Loss value : 1.0789600610733032\n",
      "Epoch 1/10 | Iteration 412/20187 | Loss value : 1.1136082410812378\n",
      "Epoch 1/10 | Iteration 413/20187 | Loss value : 1.0927107334136963\n",
      "Epoch 1/10 | Iteration 414/20187 | Loss value : 1.0833407640457153\n",
      "Epoch 1/10 | Iteration 415/20187 | Loss value : 1.0833635330200195\n",
      "Epoch 1/10 | Iteration 416/20187 | Loss value : 1.0954363346099854\n",
      "Epoch 1/10 | Iteration 417/20187 | Loss value : 1.099550485610962\n",
      "Epoch 1/10 | Iteration 418/20187 | Loss value : 1.0774966478347778\n",
      "Epoch 1/10 | Iteration 419/20187 | Loss value : 1.1473373174667358\n",
      "Epoch 1/10 | Iteration 420/20187 | Loss value : 1.0847622156143188\n",
      "Epoch 1/10 | Iteration 421/20187 | Loss value : 1.1077637672424316\n",
      "Epoch 1/10 | Iteration 422/20187 | Loss value : 1.1162651777267456\n",
      "Epoch 1/10 | Iteration 423/20187 | Loss value : 1.0960925817489624\n",
      "Epoch 1/10 | Iteration 424/20187 | Loss value : 1.1083756685256958\n",
      "Epoch 1/10 | Iteration 425/20187 | Loss value : 1.0911307334899902\n",
      "Epoch 1/10 | Iteration 426/20187 | Loss value : 1.1015453338623047\n",
      "Epoch 1/10 | Iteration 427/20187 | Loss value : 1.1238930225372314\n",
      "Epoch 1/10 | Iteration 428/20187 | Loss value : 1.1067237854003906\n",
      "Epoch 1/10 | Iteration 429/20187 | Loss value : 1.0966120958328247\n",
      "Epoch 1/10 | Iteration 430/20187 | Loss value : 1.1297472715377808\n",
      "Epoch 1/10 | Iteration 431/20187 | Loss value : 1.08198881149292\n",
      "Epoch 1/10 | Iteration 432/20187 | Loss value : 1.1885038614273071\n",
      "Epoch 1/10 | Iteration 433/20187 | Loss value : 1.1197036504745483\n",
      "Epoch 1/10 | Iteration 434/20187 | Loss value : 1.0994563102722168\n",
      "Epoch 1/10 | Iteration 435/20187 | Loss value : 1.139904499053955\n",
      "Epoch 1/10 | Iteration 436/20187 | Loss value : 1.1763378381729126\n",
      "Epoch 1/10 | Iteration 437/20187 | Loss value : 1.1035826206207275\n",
      "Epoch 1/10 | Iteration 438/20187 | Loss value : 1.0588231086730957\n",
      "Epoch 1/10 | Iteration 439/20187 | Loss value : 1.0792917013168335\n",
      "Epoch 1/10 | Iteration 440/20187 | Loss value : 1.123508095741272\n",
      "Epoch 1/10 | Iteration 441/20187 | Loss value : 1.1233646869659424\n",
      "Epoch 1/10 | Iteration 442/20187 | Loss value : 1.1138337850570679\n",
      "Epoch 1/10 | Iteration 443/20187 | Loss value : 1.13096022605896\n",
      "Epoch 1/10 | Iteration 444/20187 | Loss value : 1.105818510055542\n",
      "Epoch 1/10 | Iteration 445/20187 | Loss value : 1.1269971132278442\n",
      "Epoch 1/10 | Iteration 446/20187 | Loss value : 1.091567039489746\n",
      "Epoch 1/10 | Iteration 447/20187 | Loss value : 1.0920262336730957\n",
      "Epoch 1/10 | Iteration 448/20187 | Loss value : 1.099189281463623\n",
      "Epoch 1/10 | Iteration 449/20187 | Loss value : 1.0796177387237549\n",
      "Epoch 1/10 | Iteration 450/20187 | Loss value : 1.1334115266799927\n",
      "Epoch 1/10 | Iteration 451/20187 | Loss value : 1.1388648748397827\n",
      "Epoch 1/10 | Iteration 452/20187 | Loss value : 1.0952856540679932\n",
      "Epoch 1/10 | Iteration 453/20187 | Loss value : 1.1428954601287842\n",
      "Epoch 1/10 | Iteration 454/20187 | Loss value : 1.0992904901504517\n",
      "Epoch 1/10 | Iteration 455/20187 | Loss value : 1.1094638109207153\n",
      "Epoch 1/10 | Iteration 456/20187 | Loss value : 1.1255346536636353\n",
      "Epoch 1/10 | Iteration 457/20187 | Loss value : 1.1236106157302856\n",
      "Epoch 1/10 | Iteration 458/20187 | Loss value : 1.1296725273132324\n",
      "Epoch 1/10 | Iteration 459/20187 | Loss value : 1.1156703233718872\n",
      "Epoch 1/10 | Iteration 460/20187 | Loss value : 1.102371335029602\n",
      "Epoch 1/10 | Iteration 461/20187 | Loss value : 1.100495457649231\n",
      "Epoch 1/10 | Iteration 462/20187 | Loss value : 1.0678309202194214\n",
      "Epoch 1/10 | Iteration 463/20187 | Loss value : 1.1142083406448364\n",
      "Epoch 1/10 | Iteration 464/20187 | Loss value : 1.0966001749038696\n",
      "Epoch 1/10 | Iteration 465/20187 | Loss value : 1.0974109172821045\n",
      "Epoch 1/10 | Iteration 466/20187 | Loss value : 1.1031875610351562\n",
      "Epoch 1/10 | Iteration 467/20187 | Loss value : 1.1260206699371338\n",
      "Epoch 1/10 | Iteration 468/20187 | Loss value : 1.10030198097229\n",
      "Epoch 1/10 | Iteration 469/20187 | Loss value : 1.1015548706054688\n",
      "Epoch 1/10 | Iteration 470/20187 | Loss value : 1.106186032295227\n",
      "Epoch 1/10 | Iteration 471/20187 | Loss value : 1.084166407585144\n",
      "Epoch 1/10 | Iteration 472/20187 | Loss value : 1.106804609298706\n",
      "Epoch 1/10 | Iteration 473/20187 | Loss value : 1.044511318206787\n",
      "Epoch 1/10 | Iteration 474/20187 | Loss value : 1.0968397855758667\n",
      "Epoch 1/10 | Iteration 475/20187 | Loss value : 1.1247401237487793\n",
      "Epoch 1/10 | Iteration 476/20187 | Loss value : 1.1010075807571411\n",
      "Epoch 1/10 | Iteration 477/20187 | Loss value : 1.0744715929031372\n",
      "Epoch 1/10 | Iteration 478/20187 | Loss value : 1.0730773210525513\n",
      "Epoch 1/10 | Iteration 479/20187 | Loss value : 1.102012276649475\n",
      "Epoch 1/10 | Iteration 480/20187 | Loss value : 1.1410086154937744\n",
      "Epoch 1/10 | Iteration 481/20187 | Loss value : 1.1191891431808472\n",
      "Epoch 1/10 | Iteration 482/20187 | Loss value : 1.1258516311645508\n",
      "Epoch 1/10 | Iteration 483/20187 | Loss value : 1.0936930179595947\n",
      "Epoch 1/10 | Iteration 484/20187 | Loss value : 1.0909509658813477\n",
      "Epoch 1/10 | Iteration 485/20187 | Loss value : 1.1110154390335083\n",
      "Epoch 1/10 | Iteration 486/20187 | Loss value : 1.0777305364608765\n",
      "Epoch 1/10 | Iteration 487/20187 | Loss value : 1.1380265951156616\n",
      "Epoch 1/10 | Iteration 488/20187 | Loss value : 1.1367450952529907\n",
      "Epoch 1/10 | Iteration 489/20187 | Loss value : 1.1185212135314941\n",
      "Epoch 1/10 | Iteration 490/20187 | Loss value : 1.1216990947723389\n",
      "Epoch 1/10 | Iteration 491/20187 | Loss value : 1.0696327686309814\n",
      "Epoch 1/10 | Iteration 492/20187 | Loss value : 1.068277359008789\n",
      "Epoch 1/10 | Iteration 493/20187 | Loss value : 1.0607552528381348\n",
      "Epoch 1/10 | Iteration 494/20187 | Loss value : 1.0548397302627563\n",
      "Epoch 1/10 | Iteration 495/20187 | Loss value : 1.0850672721862793\n",
      "Epoch 1/10 | Iteration 496/20187 | Loss value : 1.1096440553665161\n",
      "Epoch 1/10 | Iteration 497/20187 | Loss value : 1.0803340673446655\n",
      "Epoch 1/10 | Iteration 498/20187 | Loss value : 1.1120551824569702\n",
      "Epoch 1/10 | Iteration 499/20187 | Loss value : 1.1263890266418457\n",
      "Epoch 1/10 | Iteration 500/20187 | Loss value : 1.1101897954940796\n",
      "Epoch 1/10 | Iteration 501/20187 | Loss value : 1.114152431488037\n",
      "Epoch 1/10 | Iteration 502/20187 | Loss value : 1.1009002923965454\n",
      "Epoch 1/10 | Iteration 503/20187 | Loss value : 1.117648959159851\n",
      "Epoch 1/10 | Iteration 504/20187 | Loss value : 1.1017053127288818\n",
      "Epoch 1/10 | Iteration 505/20187 | Loss value : 1.0912796258926392\n",
      "Epoch 1/10 | Iteration 506/20187 | Loss value : 1.1461658477783203\n",
      "Epoch 1/10 | Iteration 507/20187 | Loss value : 1.0835564136505127\n",
      "Epoch 1/10 | Iteration 508/20187 | Loss value : 1.0688730478286743\n",
      "Epoch 1/10 | Iteration 509/20187 | Loss value : 1.105594515800476\n",
      "Epoch 1/10 | Iteration 510/20187 | Loss value : 1.1186127662658691\n",
      "Epoch 1/10 | Iteration 511/20187 | Loss value : 1.1264604330062866\n",
      "Epoch 1/10 | Iteration 512/20187 | Loss value : 1.109940767288208\n",
      "Epoch 1/10 | Iteration 513/20187 | Loss value : 1.0818781852722168\n",
      "Epoch 1/10 | Iteration 514/20187 | Loss value : 1.0833051204681396\n",
      "Epoch 1/10 | Iteration 515/20187 | Loss value : 1.1013494729995728\n",
      "Epoch 1/10 | Iteration 516/20187 | Loss value : 1.0759496688842773\n",
      "Epoch 1/10 | Iteration 517/20187 | Loss value : 1.0772888660430908\n",
      "Epoch 1/10 | Iteration 518/20187 | Loss value : 1.088385820388794\n",
      "Epoch 1/10 | Iteration 519/20187 | Loss value : 1.0683115720748901\n",
      "Epoch 1/10 | Iteration 520/20187 | Loss value : 1.1297907829284668\n",
      "Epoch 1/10 | Iteration 521/20187 | Loss value : 1.0722687244415283\n",
      "Epoch 1/10 | Iteration 522/20187 | Loss value : 1.0948328971862793\n",
      "Epoch 1/10 | Iteration 523/20187 | Loss value : 1.1179965734481812\n",
      "Epoch 1/10 | Iteration 524/20187 | Loss value : 1.1191086769104004\n",
      "Epoch 1/10 | Iteration 525/20187 | Loss value : 1.0799294710159302\n",
      "Epoch 1/10 | Iteration 526/20187 | Loss value : 1.0986703634262085\n",
      "Epoch 1/10 | Iteration 527/20187 | Loss value : 1.1039347648620605\n",
      "Epoch 1/10 | Iteration 528/20187 | Loss value : 1.1567349433898926\n",
      "Epoch 1/10 | Iteration 529/20187 | Loss value : 1.1248130798339844\n",
      "Epoch 1/10 | Iteration 530/20187 | Loss value : 1.0761786699295044\n",
      "Epoch 1/10 | Iteration 531/20187 | Loss value : 1.101259708404541\n",
      "Epoch 1/10 | Iteration 532/20187 | Loss value : 1.1111341714859009\n",
      "Epoch 1/10 | Iteration 533/20187 | Loss value : 1.098722219467163\n",
      "Epoch 1/10 | Iteration 534/20187 | Loss value : 1.0854895114898682\n",
      "Epoch 1/10 | Iteration 535/20187 | Loss value : 1.1436434984207153\n",
      "Epoch 1/10 | Iteration 536/20187 | Loss value : 1.0673621892929077\n",
      "Epoch 1/10 | Iteration 537/20187 | Loss value : 1.0822430849075317\n",
      "Epoch 1/10 | Iteration 538/20187 | Loss value : 1.1228673458099365\n",
      "Epoch 1/10 | Iteration 539/20187 | Loss value : 1.1527498960494995\n",
      "Epoch 1/10 | Iteration 540/20187 | Loss value : 1.0579637289047241\n",
      "Epoch 1/10 | Iteration 541/20187 | Loss value : 1.1142899990081787\n",
      "Epoch 1/10 | Iteration 542/20187 | Loss value : 1.1232695579528809\n",
      "Epoch 1/10 | Iteration 543/20187 | Loss value : 1.1246669292449951\n",
      "Epoch 1/10 | Iteration 544/20187 | Loss value : 1.1018604040145874\n",
      "Epoch 1/10 | Iteration 545/20187 | Loss value : 1.1230058670043945\n",
      "Epoch 1/10 | Iteration 546/20187 | Loss value : 1.0749826431274414\n",
      "Epoch 1/10 | Iteration 547/20187 | Loss value : 1.1067315340042114\n",
      "Epoch 1/10 | Iteration 548/20187 | Loss value : 1.1339077949523926\n",
      "Epoch 1/10 | Iteration 549/20187 | Loss value : 1.1431771516799927\n",
      "Epoch 1/10 | Iteration 550/20187 | Loss value : 1.1063748598098755\n",
      "Epoch 1/10 | Iteration 551/20187 | Loss value : 1.1165854930877686\n",
      "Epoch 1/10 | Iteration 552/20187 | Loss value : 1.10762619972229\n",
      "Epoch 1/10 | Iteration 553/20187 | Loss value : 1.0773881673812866\n",
      "Epoch 1/10 | Iteration 554/20187 | Loss value : 1.1055481433868408\n",
      "Epoch 1/10 | Iteration 555/20187 | Loss value : 1.068282127380371\n",
      "Epoch 1/10 | Iteration 556/20187 | Loss value : 1.1016361713409424\n",
      "Epoch 1/10 | Iteration 557/20187 | Loss value : 1.0939381122589111\n",
      "Epoch 1/10 | Iteration 558/20187 | Loss value : 1.1136927604675293\n",
      "Epoch 1/10 | Iteration 559/20187 | Loss value : 1.091052532196045\n",
      "Epoch 1/10 | Iteration 560/20187 | Loss value : 1.095497727394104\n",
      "Epoch 1/10 | Iteration 561/20187 | Loss value : 1.1417869329452515\n",
      "Epoch 1/10 | Iteration 562/20187 | Loss value : 1.155178189277649\n",
      "Epoch 1/10 | Iteration 563/20187 | Loss value : 1.1547503471374512\n",
      "Epoch 1/10 | Iteration 564/20187 | Loss value : 1.1039413213729858\n",
      "Epoch 1/10 | Iteration 565/20187 | Loss value : 1.0964758396148682\n",
      "Epoch 1/10 | Iteration 566/20187 | Loss value : 1.114470362663269\n",
      "Epoch 1/10 | Iteration 567/20187 | Loss value : 1.105200171470642\n",
      "Epoch 1/10 | Iteration 568/20187 | Loss value : 1.1517958641052246\n",
      "Epoch 1/10 | Iteration 569/20187 | Loss value : 1.1405383348464966\n",
      "Epoch 1/10 | Iteration 570/20187 | Loss value : 1.125862717628479\n",
      "Epoch 1/10 | Iteration 571/20187 | Loss value : 1.0801079273223877\n",
      "Epoch 1/10 | Iteration 572/20187 | Loss value : 1.0875351428985596\n",
      "Epoch 1/10 | Iteration 573/20187 | Loss value : 1.0692042112350464\n",
      "Epoch 1/10 | Iteration 574/20187 | Loss value : 1.1048805713653564\n",
      "Epoch 1/10 | Iteration 575/20187 | Loss value : 1.0914890766143799\n",
      "Epoch 1/10 | Iteration 576/20187 | Loss value : 1.0932717323303223\n",
      "Epoch 1/10 | Iteration 577/20187 | Loss value : 1.1432719230651855\n",
      "Epoch 1/10 | Iteration 578/20187 | Loss value : 1.1104607582092285\n",
      "Epoch 1/10 | Iteration 579/20187 | Loss value : 1.1252245903015137\n",
      "Epoch 1/10 | Iteration 580/20187 | Loss value : 1.1053448915481567\n",
      "Epoch 1/10 | Iteration 581/20187 | Loss value : 1.0950219631195068\n",
      "Epoch 1/10 | Iteration 582/20187 | Loss value : 1.121937870979309\n",
      "Epoch 1/10 | Iteration 583/20187 | Loss value : 1.103052020072937\n",
      "Epoch 1/10 | Iteration 584/20187 | Loss value : 1.1390700340270996\n",
      "Epoch 1/10 | Iteration 585/20187 | Loss value : 1.10160493850708\n",
      "Epoch 1/10 | Iteration 586/20187 | Loss value : 1.095809817314148\n",
      "Epoch 1/10 | Iteration 587/20187 | Loss value : 1.1450049877166748\n",
      "Epoch 1/10 | Iteration 588/20187 | Loss value : 1.1104092597961426\n",
      "Epoch 1/10 | Iteration 589/20187 | Loss value : 1.1236541271209717\n",
      "Epoch 1/10 | Iteration 590/20187 | Loss value : 1.1316571235656738\n",
      "Epoch 1/10 | Iteration 591/20187 | Loss value : 1.1066263914108276\n",
      "Epoch 1/10 | Iteration 592/20187 | Loss value : 1.0762232542037964\n",
      "Epoch 1/10 | Iteration 593/20187 | Loss value : 1.1175395250320435\n",
      "Epoch 1/10 | Iteration 594/20187 | Loss value : 1.138364315032959\n",
      "Epoch 1/10 | Iteration 595/20187 | Loss value : 1.0943297147750854\n",
      "Epoch 1/10 | Iteration 596/20187 | Loss value : 1.0941147804260254\n",
      "Epoch 1/10 | Iteration 597/20187 | Loss value : 1.1022661924362183\n",
      "Epoch 1/10 | Iteration 598/20187 | Loss value : 1.1209710836410522\n",
      "Epoch 1/10 | Iteration 599/20187 | Loss value : 1.1218914985656738\n",
      "Epoch 1/10 | Iteration 600/20187 | Loss value : 1.0684152841567993\n",
      "Epoch 1/10 | Iteration 601/20187 | Loss value : 1.107610821723938\n",
      "Epoch 1/10 | Iteration 602/20187 | Loss value : 1.0922343730926514\n",
      "Epoch 1/10 | Iteration 603/20187 | Loss value : 1.1290042400360107\n",
      "Epoch 1/10 | Iteration 604/20187 | Loss value : 1.1677898168563843\n",
      "Epoch 1/10 | Iteration 605/20187 | Loss value : 1.0934770107269287\n",
      "Epoch 1/10 | Iteration 606/20187 | Loss value : 1.1194478273391724\n",
      "Epoch 1/10 | Iteration 607/20187 | Loss value : 1.099846363067627\n",
      "Epoch 1/10 | Iteration 608/20187 | Loss value : 1.0937433242797852\n",
      "Epoch 1/10 | Iteration 609/20187 | Loss value : 1.126153826713562\n",
      "Epoch 1/10 | Iteration 610/20187 | Loss value : 1.0978615283966064\n",
      "Epoch 1/10 | Iteration 611/20187 | Loss value : 1.1233417987823486\n",
      "Epoch 1/10 | Iteration 612/20187 | Loss value : 1.1186031103134155\n",
      "Epoch 1/10 | Iteration 613/20187 | Loss value : 1.1178202629089355\n",
      "Epoch 1/10 | Iteration 614/20187 | Loss value : 1.0986852645874023\n",
      "Epoch 1/10 | Iteration 615/20187 | Loss value : 1.104752779006958\n",
      "Epoch 1/10 | Iteration 616/20187 | Loss value : 1.1339460611343384\n",
      "Epoch 1/10 | Iteration 617/20187 | Loss value : 1.0913172960281372\n",
      "Epoch 1/10 | Iteration 618/20187 | Loss value : 1.089606761932373\n",
      "Epoch 1/10 | Iteration 619/20187 | Loss value : 1.0857255458831787\n",
      "Epoch 1/10 | Iteration 620/20187 | Loss value : 1.1103148460388184\n",
      "Epoch 1/10 | Iteration 621/20187 | Loss value : 1.109400749206543\n",
      "Epoch 1/10 | Iteration 622/20187 | Loss value : 1.1018863916397095\n",
      "Epoch 1/10 | Iteration 623/20187 | Loss value : 1.08224356174469\n",
      "Epoch 1/10 | Iteration 624/20187 | Loss value : 1.1323527097702026\n",
      "Epoch 1/10 | Iteration 625/20187 | Loss value : 1.0750871896743774\n",
      "Epoch 1/10 | Iteration 626/20187 | Loss value : 1.1253516674041748\n",
      "Epoch 1/10 | Iteration 627/20187 | Loss value : 1.1158233880996704\n",
      "Epoch 1/10 | Iteration 628/20187 | Loss value : 1.0945541858673096\n",
      "Epoch 1/10 | Iteration 629/20187 | Loss value : 1.1154271364212036\n",
      "Epoch 1/10 | Iteration 630/20187 | Loss value : 1.1441924571990967\n",
      "Epoch 1/10 | Iteration 631/20187 | Loss value : 1.0997116565704346\n",
      "Epoch 1/10 | Iteration 632/20187 | Loss value : 1.138694167137146\n",
      "Epoch 1/10 | Iteration 633/20187 | Loss value : 1.0661126375198364\n",
      "Epoch 1/10 | Iteration 634/20187 | Loss value : 1.0991591215133667\n",
      "Epoch 1/10 | Iteration 635/20187 | Loss value : 1.1003789901733398\n",
      "Epoch 1/10 | Iteration 636/20187 | Loss value : 1.1119943857192993\n",
      "Epoch 1/10 | Iteration 637/20187 | Loss value : 1.090978980064392\n",
      "Epoch 1/10 | Iteration 638/20187 | Loss value : 1.0945910215377808\n",
      "Epoch 1/10 | Iteration 639/20187 | Loss value : 1.130223035812378\n",
      "Epoch 1/10 | Iteration 640/20187 | Loss value : 1.135490894317627\n",
      "Epoch 1/10 | Iteration 641/20187 | Loss value : 1.1191411018371582\n",
      "Epoch 1/10 | Iteration 642/20187 | Loss value : 1.1122721433639526\n",
      "Epoch 1/10 | Iteration 643/20187 | Loss value : 1.1196039915084839\n",
      "Epoch 1/10 | Iteration 644/20187 | Loss value : 1.0993798971176147\n",
      "Epoch 1/10 | Iteration 645/20187 | Loss value : 1.1291594505310059\n",
      "Epoch 1/10 | Iteration 646/20187 | Loss value : 1.0983327627182007\n",
      "Epoch 1/10 | Iteration 647/20187 | Loss value : 1.1044517755508423\n",
      "Epoch 1/10 | Iteration 648/20187 | Loss value : 1.121494174003601\n",
      "Epoch 1/10 | Iteration 649/20187 | Loss value : 1.0893070697784424\n",
      "Epoch 1/10 | Iteration 650/20187 | Loss value : 1.0748450756072998\n",
      "Epoch 1/10 | Iteration 651/20187 | Loss value : 1.0998005867004395\n",
      "Epoch 1/10 | Iteration 652/20187 | Loss value : 1.1246587038040161\n",
      "Epoch 1/10 | Iteration 653/20187 | Loss value : 1.1034809350967407\n",
      "Epoch 1/10 | Iteration 654/20187 | Loss value : 1.1401889324188232\n",
      "Epoch 1/10 | Iteration 655/20187 | Loss value : 1.1195987462997437\n",
      "Epoch 1/10 | Iteration 656/20187 | Loss value : 1.0828068256378174\n",
      "Epoch 1/10 | Iteration 657/20187 | Loss value : 1.1443067789077759\n",
      "Epoch 1/10 | Iteration 658/20187 | Loss value : 1.1203254461288452\n",
      "Epoch 1/10 | Iteration 659/20187 | Loss value : 1.0971908569335938\n",
      "Epoch 1/10 | Iteration 660/20187 | Loss value : 1.078964352607727\n",
      "Epoch 1/10 | Iteration 661/20187 | Loss value : 1.0954415798187256\n",
      "Epoch 1/10 | Iteration 662/20187 | Loss value : 1.1273820400238037\n",
      "Epoch 1/10 | Iteration 663/20187 | Loss value : 1.1178619861602783\n",
      "Epoch 1/10 | Iteration 664/20187 | Loss value : 1.0855439901351929\n",
      "Epoch 1/10 | Iteration 665/20187 | Loss value : 1.1179347038269043\n",
      "Epoch 1/10 | Iteration 666/20187 | Loss value : 1.1315170526504517\n",
      "Epoch 1/10 | Iteration 667/20187 | Loss value : 1.0963114500045776\n",
      "Epoch 1/10 | Iteration 668/20187 | Loss value : 1.105934500694275\n",
      "Epoch 1/10 | Iteration 669/20187 | Loss value : 1.1254183053970337\n",
      "Epoch 1/10 | Iteration 670/20187 | Loss value : 1.122904658317566\n",
      "Epoch 1/10 | Iteration 671/20187 | Loss value : 1.109367847442627\n",
      "Epoch 1/10 | Iteration 672/20187 | Loss value : 1.147170066833496\n",
      "Epoch 1/10 | Iteration 673/20187 | Loss value : 1.0947697162628174\n",
      "Epoch 1/10 | Iteration 674/20187 | Loss value : 1.1391854286193848\n",
      "Epoch 1/10 | Iteration 675/20187 | Loss value : 1.0886348485946655\n",
      "Epoch 1/10 | Iteration 676/20187 | Loss value : 1.0931318998336792\n",
      "Epoch 1/10 | Iteration 677/20187 | Loss value : 1.134171724319458\n",
      "Epoch 1/10 | Iteration 678/20187 | Loss value : 1.123313546180725\n",
      "Epoch 1/10 | Iteration 679/20187 | Loss value : 1.080832600593567\n",
      "Epoch 1/10 | Iteration 680/20187 | Loss value : 1.1016647815704346\n",
      "Epoch 1/10 | Iteration 681/20187 | Loss value : 1.0897338390350342\n",
      "Epoch 1/10 | Iteration 682/20187 | Loss value : 1.1192328929901123\n",
      "Epoch 1/10 | Iteration 683/20187 | Loss value : 1.1009809970855713\n",
      "Epoch 1/10 | Iteration 684/20187 | Loss value : 1.0865297317504883\n",
      "Epoch 1/10 | Iteration 685/20187 | Loss value : 1.1051054000854492\n",
      "Epoch 1/10 | Iteration 686/20187 | Loss value : 1.1252270936965942\n",
      "Epoch 1/10 | Iteration 687/20187 | Loss value : 1.0598175525665283\n",
      "Epoch 1/10 | Iteration 688/20187 | Loss value : 1.0766487121582031\n",
      "Epoch 1/10 | Iteration 689/20187 | Loss value : 1.0915054082870483\n",
      "Epoch 1/10 | Iteration 690/20187 | Loss value : 1.1375272274017334\n",
      "Epoch 1/10 | Iteration 691/20187 | Loss value : 1.0968583822250366\n",
      "Epoch 1/10 | Iteration 692/20187 | Loss value : 1.145334243774414\n",
      "Epoch 1/10 | Iteration 693/20187 | Loss value : 1.0980892181396484\n",
      "Epoch 1/10 | Iteration 694/20187 | Loss value : 1.1381783485412598\n",
      "Epoch 1/10 | Iteration 695/20187 | Loss value : 1.1364505290985107\n",
      "Epoch 1/10 | Iteration 696/20187 | Loss value : 1.0998101234436035\n",
      "Epoch 1/10 | Iteration 697/20187 | Loss value : 1.1050159931182861\n",
      "Epoch 1/10 | Iteration 698/20187 | Loss value : 1.048392653465271\n",
      "Epoch 1/10 | Iteration 699/20187 | Loss value : 1.1113072633743286\n",
      "Epoch 1/10 | Iteration 700/20187 | Loss value : 1.070106863975525\n",
      "Epoch 1/10 | Iteration 701/20187 | Loss value : 1.0809270143508911\n",
      "Epoch 1/10 | Iteration 702/20187 | Loss value : 1.1051759719848633\n",
      "Epoch 1/10 | Iteration 703/20187 | Loss value : 1.117437481880188\n",
      "Epoch 1/10 | Iteration 704/20187 | Loss value : 1.1019318103790283\n",
      "Epoch 1/10 | Iteration 705/20187 | Loss value : 1.116610050201416\n",
      "Epoch 1/10 | Iteration 706/20187 | Loss value : 1.1022313833236694\n",
      "Epoch 1/10 | Iteration 707/20187 | Loss value : 1.089638352394104\n",
      "Epoch 1/10 | Iteration 708/20187 | Loss value : 1.1199231147766113\n",
      "Epoch 1/10 | Iteration 709/20187 | Loss value : 1.1116501092910767\n",
      "Epoch 1/10 | Iteration 710/20187 | Loss value : 1.083657145500183\n",
      "Epoch 1/10 | Iteration 711/20187 | Loss value : 1.1042674779891968\n",
      "Epoch 1/10 | Iteration 712/20187 | Loss value : 1.123610258102417\n",
      "Epoch 1/10 | Iteration 713/20187 | Loss value : 1.125200629234314\n",
      "Epoch 1/10 | Iteration 714/20187 | Loss value : 1.099459171295166\n",
      "Epoch 1/10 | Iteration 715/20187 | Loss value : 1.0907031297683716\n",
      "Epoch 1/10 | Iteration 716/20187 | Loss value : 1.11919367313385\n",
      "Epoch 1/10 | Iteration 717/20187 | Loss value : 1.105445384979248\n",
      "Epoch 1/10 | Iteration 718/20187 | Loss value : 1.1398087739944458\n",
      "Epoch 1/10 | Iteration 719/20187 | Loss value : 1.1397486925125122\n",
      "Epoch 1/10 | Iteration 720/20187 | Loss value : 1.1300938129425049\n",
      "Epoch 1/10 | Iteration 721/20187 | Loss value : 1.1151325702667236\n",
      "Epoch 1/10 | Iteration 722/20187 | Loss value : 1.0741711854934692\n",
      "Epoch 1/10 | Iteration 723/20187 | Loss value : 1.0808295011520386\n",
      "Epoch 1/10 | Iteration 724/20187 | Loss value : 1.0469615459442139\n",
      "Epoch 1/10 | Iteration 725/20187 | Loss value : 1.1395025253295898\n",
      "Epoch 1/10 | Iteration 726/20187 | Loss value : 1.0973552465438843\n",
      "Epoch 1/10 | Iteration 727/20187 | Loss value : 1.0909807682037354\n",
      "Epoch 1/10 | Iteration 728/20187 | Loss value : 1.0858650207519531\n",
      "Epoch 1/10 | Iteration 729/20187 | Loss value : 1.126253604888916\n",
      "Epoch 1/10 | Iteration 730/20187 | Loss value : 1.0994819402694702\n",
      "Epoch 1/10 | Iteration 731/20187 | Loss value : 1.112068772315979\n",
      "Epoch 1/10 | Iteration 732/20187 | Loss value : 1.0968663692474365\n",
      "Epoch 1/10 | Iteration 733/20187 | Loss value : 1.105712890625\n",
      "Epoch 1/10 | Iteration 734/20187 | Loss value : 1.0962300300598145\n",
      "Epoch 1/10 | Iteration 735/20187 | Loss value : 1.1340867280960083\n",
      "Epoch 1/10 | Iteration 736/20187 | Loss value : 1.1144481897354126\n",
      "Epoch 1/10 | Iteration 737/20187 | Loss value : 1.08555269241333\n",
      "Epoch 1/10 | Iteration 738/20187 | Loss value : 1.0790314674377441\n",
      "Epoch 1/10 | Iteration 739/20187 | Loss value : 1.1242867708206177\n",
      "Epoch 1/10 | Iteration 740/20187 | Loss value : 1.0670868158340454\n",
      "Epoch 1/10 | Iteration 741/20187 | Loss value : 1.0906493663787842\n",
      "Epoch 1/10 | Iteration 742/20187 | Loss value : 1.0682272911071777\n",
      "Epoch 1/10 | Iteration 743/20187 | Loss value : 1.1603437662124634\n",
      "Epoch 1/10 | Iteration 744/20187 | Loss value : 1.1089270114898682\n",
      "Epoch 1/10 | Iteration 745/20187 | Loss value : 1.108731985092163\n",
      "Epoch 1/10 | Iteration 746/20187 | Loss value : 1.1228346824645996\n",
      "Epoch 1/10 | Iteration 747/20187 | Loss value : 1.112808346748352\n",
      "Epoch 1/10 | Iteration 748/20187 | Loss value : 1.1432651281356812\n",
      "Epoch 1/10 | Iteration 749/20187 | Loss value : 1.0730836391448975\n",
      "Epoch 1/10 | Iteration 750/20187 | Loss value : 1.1077558994293213\n",
      "Epoch 1/10 | Iteration 751/20187 | Loss value : 1.0894356966018677\n",
      "Epoch 1/10 | Iteration 752/20187 | Loss value : 1.136062502861023\n",
      "Epoch 1/10 | Iteration 753/20187 | Loss value : 1.1260709762573242\n",
      "Epoch 1/10 | Iteration 754/20187 | Loss value : 1.1359702348709106\n",
      "Epoch 1/10 | Iteration 755/20187 | Loss value : 1.0743967294692993\n",
      "Epoch 1/10 | Iteration 756/20187 | Loss value : 1.0470619201660156\n",
      "Epoch 1/10 | Iteration 757/20187 | Loss value : 1.102735161781311\n",
      "Epoch 1/10 | Iteration 758/20187 | Loss value : 1.082826852798462\n",
      "Epoch 1/10 | Iteration 759/20187 | Loss value : 1.1055378913879395\n",
      "Epoch 1/10 | Iteration 760/20187 | Loss value : 1.1770930290222168\n",
      "Epoch 1/10 | Iteration 761/20187 | Loss value : 1.11287522315979\n",
      "Epoch 1/10 | Iteration 762/20187 | Loss value : 1.1379592418670654\n",
      "Epoch 1/10 | Iteration 763/20187 | Loss value : 1.1012388467788696\n",
      "Epoch 1/10 | Iteration 764/20187 | Loss value : 1.1246240139007568\n",
      "Epoch 1/10 | Iteration 765/20187 | Loss value : 1.137251377105713\n",
      "Epoch 1/10 | Iteration 766/20187 | Loss value : 1.135271668434143\n",
      "Epoch 1/10 | Iteration 767/20187 | Loss value : 1.1155304908752441\n",
      "Epoch 1/10 | Iteration 768/20187 | Loss value : 1.102468490600586\n",
      "Epoch 1/10 | Iteration 769/20187 | Loss value : 1.0939457416534424\n",
      "Epoch 1/10 | Iteration 770/20187 | Loss value : 1.0918439626693726\n",
      "Epoch 1/10 | Iteration 771/20187 | Loss value : 1.1285127401351929\n",
      "Epoch 1/10 | Iteration 772/20187 | Loss value : 1.1252080202102661\n",
      "Epoch 1/10 | Iteration 773/20187 | Loss value : 1.166101098060608\n",
      "Epoch 1/10 | Iteration 774/20187 | Loss value : 1.0885577201843262\n",
      "Epoch 1/10 | Iteration 775/20187 | Loss value : 1.0981425046920776\n",
      "Epoch 1/10 | Iteration 776/20187 | Loss value : 1.112562894821167\n",
      "Epoch 1/10 | Iteration 777/20187 | Loss value : 1.1153172254562378\n",
      "Epoch 1/10 | Iteration 778/20187 | Loss value : 1.0867356061935425\n",
      "Epoch 1/10 | Iteration 779/20187 | Loss value : 1.0907528400421143\n",
      "Epoch 1/10 | Iteration 780/20187 | Loss value : 1.1304481029510498\n",
      "Epoch 1/10 | Iteration 781/20187 | Loss value : 1.1005265712738037\n",
      "Epoch 1/10 | Iteration 782/20187 | Loss value : 1.0953264236450195\n",
      "Epoch 1/10 | Iteration 783/20187 | Loss value : 1.1194720268249512\n",
      "Epoch 1/10 | Iteration 784/20187 | Loss value : 1.1350959539413452\n",
      "Epoch 1/10 | Iteration 785/20187 | Loss value : 1.1078473329544067\n",
      "Epoch 1/10 | Iteration 786/20187 | Loss value : 1.135617733001709\n",
      "Epoch 1/10 | Iteration 787/20187 | Loss value : 1.1256120204925537\n",
      "Epoch 1/10 | Iteration 788/20187 | Loss value : 1.1155164241790771\n",
      "Epoch 1/10 | Iteration 789/20187 | Loss value : 1.1399073600769043\n",
      "Epoch 1/10 | Iteration 790/20187 | Loss value : 1.1359373331069946\n",
      "Epoch 1/10 | Iteration 791/20187 | Loss value : 1.1191718578338623\n",
      "Epoch 1/10 | Iteration 792/20187 | Loss value : 1.1125303506851196\n",
      "Epoch 1/10 | Iteration 793/20187 | Loss value : 1.1350820064544678\n",
      "Epoch 1/10 | Iteration 794/20187 | Loss value : 1.1091930866241455\n",
      "Epoch 1/10 | Iteration 795/20187 | Loss value : 1.086540699005127\n",
      "Epoch 1/10 | Iteration 796/20187 | Loss value : 1.0653756856918335\n",
      "Epoch 1/10 | Iteration 797/20187 | Loss value : 1.1119612455368042\n",
      "Epoch 1/10 | Iteration 798/20187 | Loss value : 1.101702332496643\n",
      "Epoch 1/10 | Iteration 799/20187 | Loss value : 1.118129014968872\n",
      "Epoch 1/10 | Iteration 800/20187 | Loss value : 1.1124080419540405\n",
      "Epoch 1/10 | Iteration 801/20187 | Loss value : 1.0929920673370361\n",
      "Epoch 1/10 | Iteration 802/20187 | Loss value : 1.0999691486358643\n",
      "Epoch 1/10 | Iteration 803/20187 | Loss value : 1.100913643836975\n",
      "Epoch 1/10 | Iteration 804/20187 | Loss value : 1.095423936843872\n",
      "Epoch 1/10 | Iteration 805/20187 | Loss value : 1.0855084657669067\n",
      "Epoch 1/10 | Iteration 806/20187 | Loss value : 1.1079734563827515\n",
      "Epoch 1/10 | Iteration 807/20187 | Loss value : 1.1038200855255127\n",
      "Epoch 1/10 | Iteration 808/20187 | Loss value : 1.0661051273345947\n",
      "Epoch 1/10 | Iteration 809/20187 | Loss value : 1.1459816694259644\n",
      "Epoch 1/10 | Iteration 810/20187 | Loss value : 1.150801420211792\n",
      "Epoch 1/10 | Iteration 811/20187 | Loss value : 1.0907378196716309\n",
      "Epoch 1/10 | Iteration 812/20187 | Loss value : 1.1548476219177246\n",
      "Epoch 1/10 | Iteration 813/20187 | Loss value : 1.097609281539917\n",
      "Epoch 1/10 | Iteration 814/20187 | Loss value : 1.1380982398986816\n",
      "Epoch 1/10 | Iteration 815/20187 | Loss value : 1.0873744487762451\n",
      "Epoch 1/10 | Iteration 816/20187 | Loss value : 1.1226481199264526\n",
      "Epoch 1/10 | Iteration 817/20187 | Loss value : 1.1222052574157715\n",
      "Epoch 1/10 | Iteration 818/20187 | Loss value : 1.1336873769760132\n",
      "Epoch 1/10 | Iteration 819/20187 | Loss value : 1.1021614074707031\n",
      "Epoch 1/10 | Iteration 820/20187 | Loss value : 1.1058462858200073\n",
      "Epoch 1/10 | Iteration 821/20187 | Loss value : 1.1143686771392822\n",
      "Epoch 1/10 | Iteration 822/20187 | Loss value : 1.0732651948928833\n",
      "Epoch 1/10 | Iteration 823/20187 | Loss value : 1.0976642370224\n",
      "Epoch 1/10 | Iteration 824/20187 | Loss value : 1.0902303457260132\n",
      "Epoch 1/10 | Iteration 825/20187 | Loss value : 1.1116595268249512\n",
      "Epoch 1/10 | Iteration 826/20187 | Loss value : 1.1103055477142334\n",
      "Epoch 1/10 | Iteration 827/20187 | Loss value : 1.1157827377319336\n",
      "Epoch 1/10 | Iteration 828/20187 | Loss value : 1.0815870761871338\n",
      "Epoch 1/10 | Iteration 829/20187 | Loss value : 1.1502686738967896\n",
      "Epoch 1/10 | Iteration 830/20187 | Loss value : 1.0869330167770386\n",
      "Epoch 1/10 | Iteration 831/20187 | Loss value : 1.1031914949417114\n",
      "Epoch 1/10 | Iteration 832/20187 | Loss value : 1.1131107807159424\n",
      "Epoch 1/10 | Iteration 833/20187 | Loss value : 1.1179018020629883\n",
      "Epoch 1/10 | Iteration 834/20187 | Loss value : 1.1279345750808716\n",
      "Epoch 1/10 | Iteration 835/20187 | Loss value : 1.080775499343872\n",
      "Epoch 1/10 | Iteration 836/20187 | Loss value : 1.134818196296692\n",
      "Epoch 1/10 | Iteration 837/20187 | Loss value : 1.1029738187789917\n",
      "Epoch 1/10 | Iteration 838/20187 | Loss value : 1.0723090171813965\n",
      "Epoch 1/10 | Iteration 839/20187 | Loss value : 1.0777559280395508\n",
      "Epoch 1/10 | Iteration 840/20187 | Loss value : 1.0977598428726196\n",
      "Epoch 1/10 | Iteration 841/20187 | Loss value : 1.1358698606491089\n",
      "Epoch 1/10 | Iteration 842/20187 | Loss value : 1.080168604850769\n",
      "Epoch 1/10 | Iteration 843/20187 | Loss value : 1.100844144821167\n",
      "Epoch 1/10 | Iteration 844/20187 | Loss value : 1.1587305068969727\n",
      "Epoch 1/10 | Iteration 845/20187 | Loss value : 1.075434923171997\n",
      "Epoch 1/10 | Iteration 846/20187 | Loss value : 1.0907394886016846\n",
      "Epoch 1/10 | Iteration 847/20187 | Loss value : 1.1409262418746948\n",
      "Epoch 1/10 | Iteration 848/20187 | Loss value : 1.0808145999908447\n",
      "Epoch 1/10 | Iteration 849/20187 | Loss value : 1.1038011312484741\n",
      "Epoch 1/10 | Iteration 850/20187 | Loss value : 1.1407290697097778\n",
      "Epoch 1/10 | Iteration 851/20187 | Loss value : 1.0953172445297241\n",
      "Epoch 1/10 | Iteration 852/20187 | Loss value : 1.0948446989059448\n",
      "Epoch 1/10 | Iteration 853/20187 | Loss value : 1.1081005334854126\n",
      "Epoch 1/10 | Iteration 854/20187 | Loss value : 1.0992653369903564\n",
      "Epoch 1/10 | Iteration 855/20187 | Loss value : 1.1232147216796875\n",
      "Epoch 1/10 | Iteration 856/20187 | Loss value : 1.1042650938034058\n",
      "Epoch 1/10 | Iteration 857/20187 | Loss value : 1.11485755443573\n",
      "Epoch 1/10 | Iteration 858/20187 | Loss value : 1.096138834953308\n",
      "Epoch 1/10 | Iteration 859/20187 | Loss value : 1.13359797000885\n",
      "Epoch 1/10 | Iteration 860/20187 | Loss value : 1.0971390008926392\n",
      "Epoch 1/10 | Iteration 861/20187 | Loss value : 1.1134949922561646\n",
      "Epoch 1/10 | Iteration 862/20187 | Loss value : 1.087916374206543\n",
      "Epoch 1/10 | Iteration 863/20187 | Loss value : 1.1342658996582031\n",
      "Epoch 1/10 | Iteration 864/20187 | Loss value : 1.127429485321045\n",
      "Epoch 1/10 | Iteration 865/20187 | Loss value : 1.1120779514312744\n",
      "Epoch 1/10 | Iteration 866/20187 | Loss value : 1.0637308359146118\n",
      "Epoch 1/10 | Iteration 867/20187 | Loss value : 1.102562427520752\n",
      "Epoch 1/10 | Iteration 868/20187 | Loss value : 1.1120561361312866\n",
      "Epoch 1/10 | Iteration 869/20187 | Loss value : 1.1101511716842651\n",
      "Epoch 1/10 | Iteration 870/20187 | Loss value : 1.1110516786575317\n",
      "Epoch 1/10 | Iteration 871/20187 | Loss value : 1.121551513671875\n",
      "Epoch 1/10 | Iteration 872/20187 | Loss value : 1.1231846809387207\n",
      "Epoch 1/10 | Iteration 873/20187 | Loss value : 1.0830892324447632\n",
      "Epoch 1/10 | Iteration 874/20187 | Loss value : 1.0975868701934814\n",
      "Epoch 1/10 | Iteration 875/20187 | Loss value : 1.098078727722168\n",
      "Epoch 1/10 | Iteration 876/20187 | Loss value : 1.1801992654800415\n",
      "Epoch 1/10 | Iteration 877/20187 | Loss value : 1.156436562538147\n",
      "Epoch 1/10 | Iteration 878/20187 | Loss value : 1.1172086000442505\n",
      "Epoch 1/10 | Iteration 879/20187 | Loss value : 1.1220712661743164\n",
      "Epoch 1/10 | Iteration 880/20187 | Loss value : 1.1350679397583008\n",
      "Epoch 1/10 | Iteration 881/20187 | Loss value : 1.0774388313293457\n",
      "Epoch 1/10 | Iteration 882/20187 | Loss value : 1.0963903665542603\n",
      "Epoch 1/10 | Iteration 883/20187 | Loss value : 1.0912572145462036\n",
      "Epoch 1/10 | Iteration 884/20187 | Loss value : 1.0927035808563232\n",
      "Epoch 1/10 | Iteration 885/20187 | Loss value : 1.107048511505127\n",
      "Epoch 1/10 | Iteration 886/20187 | Loss value : 1.1316272020339966\n",
      "Epoch 1/10 | Iteration 887/20187 | Loss value : 1.1229735612869263\n",
      "Epoch 1/10 | Iteration 888/20187 | Loss value : 1.1219055652618408\n",
      "Epoch 1/10 | Iteration 889/20187 | Loss value : 1.0810043811798096\n",
      "Epoch 1/10 | Iteration 890/20187 | Loss value : 1.1082634925842285\n",
      "Epoch 1/10 | Iteration 891/20187 | Loss value : 1.1388884782791138\n",
      "Epoch 1/10 | Iteration 892/20187 | Loss value : 1.115587592124939\n",
      "Epoch 1/10 | Iteration 893/20187 | Loss value : 1.0614336729049683\n",
      "Epoch 1/10 | Iteration 894/20187 | Loss value : 1.1009036302566528\n",
      "Epoch 1/10 | Iteration 895/20187 | Loss value : 1.0945411920547485\n",
      "Epoch 1/10 | Iteration 896/20187 | Loss value : 1.090945839881897\n",
      "Epoch 1/10 | Iteration 897/20187 | Loss value : 1.0793499946594238\n",
      "Epoch 1/10 | Iteration 898/20187 | Loss value : 1.159866452217102\n",
      "Epoch 1/10 | Iteration 899/20187 | Loss value : 1.1329624652862549\n",
      "Epoch 1/10 | Iteration 900/20187 | Loss value : 1.103030800819397\n",
      "Epoch 1/10 | Iteration 901/20187 | Loss value : 1.1096501350402832\n",
      "Epoch 1/10 | Iteration 902/20187 | Loss value : 1.1171966791152954\n",
      "Epoch 1/10 | Iteration 903/20187 | Loss value : 1.0745903253555298\n",
      "Epoch 1/10 | Iteration 904/20187 | Loss value : 1.0827854871749878\n",
      "Epoch 1/10 | Iteration 905/20187 | Loss value : 1.1031821966171265\n",
      "Epoch 1/10 | Iteration 906/20187 | Loss value : 1.0919376611709595\n",
      "Epoch 1/10 | Iteration 907/20187 | Loss value : 1.1394867897033691\n",
      "Epoch 1/10 | Iteration 908/20187 | Loss value : 1.1358141899108887\n",
      "Epoch 1/10 | Iteration 909/20187 | Loss value : 1.1548296213150024\n",
      "Epoch 1/10 | Iteration 910/20187 | Loss value : 1.0891772508621216\n",
      "Epoch 1/10 | Iteration 911/20187 | Loss value : 1.0879089832305908\n",
      "Epoch 1/10 | Iteration 912/20187 | Loss value : 1.1063300371170044\n",
      "Epoch 1/10 | Iteration 913/20187 | Loss value : 1.1181145906448364\n",
      "Epoch 1/10 | Iteration 914/20187 | Loss value : 1.086517572402954\n",
      "Epoch 1/10 | Iteration 915/20187 | Loss value : 1.0920354127883911\n",
      "Epoch 1/10 | Iteration 916/20187 | Loss value : 1.0995806455612183\n",
      "Epoch 1/10 | Iteration 917/20187 | Loss value : 1.1127517223358154\n",
      "Epoch 1/10 | Iteration 918/20187 | Loss value : 1.074213981628418\n",
      "Epoch 1/10 | Iteration 919/20187 | Loss value : 1.1070585250854492\n",
      "Epoch 1/10 | Iteration 920/20187 | Loss value : 1.0747586488723755\n",
      "Epoch 1/10 | Iteration 921/20187 | Loss value : 1.0875552892684937\n",
      "Epoch 1/10 | Iteration 922/20187 | Loss value : 1.132733941078186\n",
      "Epoch 1/10 | Iteration 923/20187 | Loss value : 1.099428415298462\n",
      "Epoch 1/10 | Iteration 924/20187 | Loss value : 1.1360584497451782\n",
      "Epoch 1/10 | Iteration 925/20187 | Loss value : 1.0916677713394165\n",
      "Epoch 1/10 | Iteration 926/20187 | Loss value : 1.075933814048767\n",
      "Epoch 1/10 | Iteration 927/20187 | Loss value : 1.1022599935531616\n",
      "Epoch 1/10 | Iteration 928/20187 | Loss value : 1.1496237516403198\n",
      "Epoch 1/10 | Iteration 929/20187 | Loss value : 1.0876505374908447\n",
      "Epoch 1/10 | Iteration 930/20187 | Loss value : 1.1219837665557861\n",
      "Epoch 1/10 | Iteration 931/20187 | Loss value : 1.0958620309829712\n",
      "Epoch 1/10 | Iteration 932/20187 | Loss value : 1.1193902492523193\n",
      "Epoch 1/10 | Iteration 933/20187 | Loss value : 1.0704587697982788\n",
      "Epoch 1/10 | Iteration 934/20187 | Loss value : 1.1089396476745605\n",
      "Epoch 1/10 | Iteration 935/20187 | Loss value : 1.1165177822113037\n",
      "Epoch 1/10 | Iteration 936/20187 | Loss value : 1.0951647758483887\n",
      "Epoch 1/10 | Iteration 937/20187 | Loss value : 1.0946334600448608\n",
      "Epoch 1/10 | Iteration 938/20187 | Loss value : 1.1075810194015503\n",
      "Epoch 1/10 | Iteration 939/20187 | Loss value : 1.1306471824645996\n",
      "Epoch 1/10 | Iteration 940/20187 | Loss value : 1.1333091259002686\n",
      "Epoch 1/10 | Iteration 941/20187 | Loss value : 1.1194977760314941\n",
      "Epoch 1/10 | Iteration 942/20187 | Loss value : 1.0977935791015625\n",
      "Epoch 1/10 | Iteration 943/20187 | Loss value : 1.0999226570129395\n",
      "Epoch 1/10 | Iteration 944/20187 | Loss value : 1.1284301280975342\n",
      "Epoch 1/10 | Iteration 945/20187 | Loss value : 1.1169430017471313\n",
      "Epoch 1/10 | Iteration 946/20187 | Loss value : 1.1116033792495728\n",
      "Epoch 1/10 | Iteration 947/20187 | Loss value : 1.126695990562439\n",
      "Epoch 1/10 | Iteration 948/20187 | Loss value : 1.112419605255127\n",
      "Epoch 1/10 | Iteration 949/20187 | Loss value : 1.0849534273147583\n",
      "Epoch 1/10 | Iteration 950/20187 | Loss value : 1.073189377784729\n",
      "Epoch 1/10 | Iteration 951/20187 | Loss value : 1.1104187965393066\n",
      "Epoch 1/10 | Iteration 952/20187 | Loss value : 1.1037421226501465\n",
      "Epoch 1/10 | Iteration 953/20187 | Loss value : 1.0988906621932983\n",
      "Epoch 1/10 | Iteration 954/20187 | Loss value : 1.103206753730774\n",
      "Epoch 1/10 | Iteration 955/20187 | Loss value : 1.0878100395202637\n",
      "Epoch 1/10 | Iteration 956/20187 | Loss value : 1.1238659620285034\n",
      "Epoch 1/10 | Iteration 957/20187 | Loss value : 1.1352152824401855\n",
      "Epoch 1/10 | Iteration 958/20187 | Loss value : 1.0831711292266846\n",
      "Epoch 1/10 | Iteration 959/20187 | Loss value : 1.0934351682662964\n",
      "Epoch 1/10 | Iteration 960/20187 | Loss value : 1.1230273246765137\n",
      "Epoch 1/10 | Iteration 961/20187 | Loss value : 1.0484460592269897\n",
      "Epoch 1/10 | Iteration 962/20187 | Loss value : 1.142706274986267\n",
      "Epoch 1/10 | Iteration 963/20187 | Loss value : 1.118823766708374\n",
      "Epoch 1/10 | Iteration 964/20187 | Loss value : 1.1166932582855225\n",
      "Epoch 1/10 | Iteration 965/20187 | Loss value : 1.119826316833496\n",
      "Epoch 1/10 | Iteration 966/20187 | Loss value : 1.1022615432739258\n",
      "Epoch 1/10 | Iteration 967/20187 | Loss value : 1.0814614295959473\n",
      "Epoch 1/10 | Iteration 968/20187 | Loss value : 1.1144731044769287\n",
      "Epoch 1/10 | Iteration 969/20187 | Loss value : 1.0896722078323364\n",
      "Epoch 1/10 | Iteration 970/20187 | Loss value : 1.1083741188049316\n",
      "Epoch 1/10 | Iteration 971/20187 | Loss value : 1.1448818445205688\n",
      "Epoch 1/10 | Iteration 972/20187 | Loss value : 1.128907561302185\n",
      "Epoch 1/10 | Iteration 973/20187 | Loss value : 1.0876014232635498\n",
      "Epoch 1/10 | Iteration 974/20187 | Loss value : 1.1092418432235718\n",
      "Epoch 1/10 | Iteration 975/20187 | Loss value : 1.1152317523956299\n",
      "Epoch 1/10 | Iteration 976/20187 | Loss value : 1.118152141571045\n",
      "Epoch 1/10 | Iteration 977/20187 | Loss value : 1.114121675491333\n",
      "Epoch 1/10 | Iteration 978/20187 | Loss value : 1.0908602476119995\n",
      "Epoch 1/10 | Iteration 979/20187 | Loss value : 1.164732813835144\n",
      "Epoch 1/10 | Iteration 980/20187 | Loss value : 1.1115808486938477\n",
      "Epoch 1/10 | Iteration 981/20187 | Loss value : 1.0477356910705566\n",
      "Epoch 1/10 | Iteration 982/20187 | Loss value : 1.1005253791809082\n",
      "Epoch 1/10 | Iteration 983/20187 | Loss value : 1.078281283378601\n",
      "Epoch 1/10 | Iteration 984/20187 | Loss value : 1.098618507385254\n",
      "Epoch 1/10 | Iteration 985/20187 | Loss value : 1.1551581621170044\n",
      "Epoch 1/10 | Iteration 986/20187 | Loss value : 1.120421051979065\n",
      "Epoch 1/10 | Iteration 987/20187 | Loss value : 1.088324785232544\n",
      "Epoch 1/10 | Iteration 988/20187 | Loss value : 1.1181398630142212\n",
      "Epoch 1/10 | Iteration 989/20187 | Loss value : 1.1392914056777954\n",
      "Epoch 1/10 | Iteration 990/20187 | Loss value : 1.1235771179199219\n",
      "Epoch 1/10 | Iteration 991/20187 | Loss value : 1.0733885765075684\n",
      "Epoch 1/10 | Iteration 992/20187 | Loss value : 1.1174263954162598\n",
      "Epoch 1/10 | Iteration 993/20187 | Loss value : 1.104494571685791\n",
      "Epoch 1/10 | Iteration 994/20187 | Loss value : 1.1070942878723145\n",
      "Epoch 1/10 | Iteration 995/20187 | Loss value : 1.1148605346679688\n",
      "Epoch 1/10 | Iteration 996/20187 | Loss value : 1.0991696119308472\n",
      "Epoch 1/10 | Iteration 997/20187 | Loss value : 1.0965310335159302\n",
      "Epoch 1/10 | Iteration 998/20187 | Loss value : 1.1274383068084717\n",
      "Epoch 1/10 | Iteration 999/20187 | Loss value : 1.1006159782409668\n",
      "Epoch 1/10 | Iteration 1000/20187 | Loss value : 1.1153491735458374\n",
      "Epoch 1/10 | Iteration 1001/20187 | Loss value : 1.1001924276351929\n",
      "Epoch 1/10 | Iteration 1002/20187 | Loss value : 1.092616319656372\n",
      "Epoch 1/10 | Iteration 1003/20187 | Loss value : 1.1124045848846436\n",
      "Epoch 1/10 | Iteration 1004/20187 | Loss value : 1.088750958442688\n",
      "Epoch 1/10 | Iteration 1005/20187 | Loss value : 1.1233601570129395\n",
      "Epoch 1/10 | Iteration 1006/20187 | Loss value : 1.1413286924362183\n",
      "Epoch 1/10 | Iteration 1007/20187 | Loss value : 1.1009869575500488\n",
      "Epoch 1/10 | Iteration 1008/20187 | Loss value : 1.1312695741653442\n",
      "Epoch 1/10 | Iteration 1009/20187 | Loss value : 1.1444811820983887\n",
      "Epoch 1/10 | Iteration 1010/20187 | Loss value : 1.1244704723358154\n",
      "Epoch 1/10 | Iteration 1011/20187 | Loss value : 1.0740962028503418\n",
      "Epoch 1/10 | Iteration 1012/20187 | Loss value : 1.1182256937026978\n",
      "Epoch 1/10 | Iteration 1013/20187 | Loss value : 1.0718635320663452\n",
      "Epoch 1/10 | Iteration 1014/20187 | Loss value : 1.1091898679733276\n",
      "Epoch 1/10 | Iteration 1015/20187 | Loss value : 1.112228274345398\n",
      "Epoch 1/10 | Iteration 1016/20187 | Loss value : 1.1485403776168823\n",
      "Epoch 1/10 | Iteration 1017/20187 | Loss value : 1.0936065912246704\n",
      "Epoch 1/10 | Iteration 1018/20187 | Loss value : 1.1130622625350952\n",
      "Epoch 1/10 | Iteration 1019/20187 | Loss value : 1.104646921157837\n",
      "Epoch 1/10 | Iteration 1020/20187 | Loss value : 1.088313341140747\n",
      "Epoch 1/10 | Iteration 1021/20187 | Loss value : 1.0960880517959595\n",
      "Epoch 1/10 | Iteration 1022/20187 | Loss value : 1.104231834411621\n",
      "Epoch 1/10 | Iteration 1023/20187 | Loss value : 1.0809924602508545\n",
      "Epoch 1/10 | Iteration 1024/20187 | Loss value : 1.145858645439148\n",
      "Epoch 1/10 | Iteration 1025/20187 | Loss value : 1.1114078760147095\n",
      "Epoch 1/10 | Iteration 1026/20187 | Loss value : 1.0595048666000366\n",
      "Epoch 1/10 | Iteration 1027/20187 | Loss value : 1.0942155122756958\n",
      "Epoch 1/10 | Iteration 1028/20187 | Loss value : 1.1027110815048218\n",
      "Epoch 1/10 | Iteration 1029/20187 | Loss value : 1.1250412464141846\n",
      "Epoch 1/10 | Iteration 1030/20187 | Loss value : 1.114188551902771\n",
      "Epoch 1/10 | Iteration 1031/20187 | Loss value : 1.1185121536254883\n",
      "Epoch 1/10 | Iteration 1032/20187 | Loss value : 1.101837396621704\n",
      "Epoch 1/10 | Iteration 1033/20187 | Loss value : 1.0669524669647217\n",
      "Epoch 1/10 | Iteration 1034/20187 | Loss value : 1.1256223917007446\n",
      "Epoch 1/10 | Iteration 1035/20187 | Loss value : 1.1325722932815552\n",
      "Epoch 1/10 | Iteration 1036/20187 | Loss value : 1.1437007188796997\n",
      "Epoch 1/10 | Iteration 1037/20187 | Loss value : 1.075494408607483\n",
      "Epoch 1/10 | Iteration 1038/20187 | Loss value : 1.0608608722686768\n",
      "Epoch 1/10 | Iteration 1039/20187 | Loss value : 1.103179931640625\n",
      "Epoch 1/10 | Iteration 1040/20187 | Loss value : 1.110386848449707\n",
      "Epoch 1/10 | Iteration 1041/20187 | Loss value : 1.0934215784072876\n",
      "Epoch 1/10 | Iteration 1042/20187 | Loss value : 1.1210451126098633\n",
      "Epoch 1/10 | Iteration 1043/20187 | Loss value : 1.104810118675232\n",
      "Epoch 1/10 | Iteration 1044/20187 | Loss value : 1.1246892213821411\n",
      "Epoch 1/10 | Iteration 1045/20187 | Loss value : 1.0617725849151611\n",
      "Epoch 1/10 | Iteration 1046/20187 | Loss value : 1.1382379531860352\n",
      "Epoch 1/10 | Iteration 1047/20187 | Loss value : 1.1020708084106445\n",
      "Epoch 1/10 | Iteration 1048/20187 | Loss value : 1.1108322143554688\n",
      "Epoch 1/10 | Iteration 1049/20187 | Loss value : 1.1068336963653564\n",
      "Epoch 1/10 | Iteration 1050/20187 | Loss value : 1.0978823900222778\n",
      "Epoch 1/10 | Iteration 1051/20187 | Loss value : 1.0949790477752686\n",
      "Epoch 1/10 | Iteration 1052/20187 | Loss value : 1.1248555183410645\n",
      "Epoch 1/10 | Iteration 1053/20187 | Loss value : 1.0792080163955688\n",
      "Epoch 1/10 | Iteration 1054/20187 | Loss value : 1.131350040435791\n",
      "Epoch 1/10 | Iteration 1055/20187 | Loss value : 1.1227070093154907\n",
      "Epoch 1/10 | Iteration 1056/20187 | Loss value : 1.0802541971206665\n",
      "Epoch 1/10 | Iteration 1057/20187 | Loss value : 1.1297483444213867\n",
      "Epoch 1/10 | Iteration 1058/20187 | Loss value : 1.0913660526275635\n",
      "Epoch 1/10 | Iteration 1059/20187 | Loss value : 1.1120786666870117\n",
      "Epoch 1/10 | Iteration 1060/20187 | Loss value : 1.0705113410949707\n",
      "Epoch 1/10 | Iteration 1061/20187 | Loss value : 1.1115450859069824\n",
      "Epoch 1/10 | Iteration 1062/20187 | Loss value : 1.106310248374939\n",
      "Epoch 1/10 | Iteration 1063/20187 | Loss value : 1.0852713584899902\n",
      "Epoch 1/10 | Iteration 1064/20187 | Loss value : 1.0789690017700195\n",
      "Epoch 1/10 | Iteration 1065/20187 | Loss value : 1.1334115266799927\n",
      "Epoch 1/10 | Iteration 1066/20187 | Loss value : 1.0691325664520264\n",
      "Epoch 1/10 | Iteration 1067/20187 | Loss value : 1.1184935569763184\n",
      "Epoch 1/10 | Iteration 1068/20187 | Loss value : 1.102665901184082\n",
      "Epoch 1/10 | Iteration 1069/20187 | Loss value : 1.1046847105026245\n",
      "Epoch 1/10 | Iteration 1070/20187 | Loss value : 1.0591633319854736\n",
      "Epoch 1/10 | Iteration 1071/20187 | Loss value : 1.0918066501617432\n",
      "Epoch 1/10 | Iteration 1072/20187 | Loss value : 1.082578182220459\n",
      "Epoch 1/10 | Iteration 1073/20187 | Loss value : 1.1336259841918945\n",
      "Epoch 1/10 | Iteration 1074/20187 | Loss value : 1.1239465475082397\n",
      "Epoch 1/10 | Iteration 1075/20187 | Loss value : 1.1312278509140015\n",
      "Epoch 1/10 | Iteration 1076/20187 | Loss value : 1.0672235488891602\n",
      "Epoch 1/10 | Iteration 1077/20187 | Loss value : 1.1511863470077515\n",
      "Epoch 1/10 | Iteration 1078/20187 | Loss value : 1.1170345544815063\n",
      "Epoch 1/10 | Iteration 1079/20187 | Loss value : 1.0715795755386353\n",
      "Epoch 1/10 | Iteration 1080/20187 | Loss value : 1.158994436264038\n",
      "Epoch 1/10 | Iteration 1081/20187 | Loss value : 1.1054214239120483\n",
      "Epoch 1/10 | Iteration 1082/20187 | Loss value : 1.1191315650939941\n",
      "Epoch 1/10 | Iteration 1083/20187 | Loss value : 1.0910965204238892\n",
      "Epoch 1/10 | Iteration 1084/20187 | Loss value : 1.1254215240478516\n",
      "Epoch 1/10 | Iteration 1085/20187 | Loss value : 1.0991417169570923\n",
      "Epoch 1/10 | Iteration 1086/20187 | Loss value : 1.0987536907196045\n",
      "Epoch 1/10 | Iteration 1087/20187 | Loss value : 1.1290767192840576\n",
      "Epoch 1/10 | Iteration 1088/20187 | Loss value : 1.130899429321289\n",
      "Epoch 1/10 | Iteration 1089/20187 | Loss value : 1.0895278453826904\n",
      "Epoch 1/10 | Iteration 1090/20187 | Loss value : 1.1277259588241577\n",
      "Epoch 1/10 | Iteration 1091/20187 | Loss value : 1.087285041809082\n",
      "Epoch 1/10 | Iteration 1092/20187 | Loss value : 1.0880016088485718\n",
      "Epoch 1/10 | Iteration 1093/20187 | Loss value : 1.105692744255066\n",
      "Epoch 1/10 | Iteration 1094/20187 | Loss value : 1.1105964183807373\n",
      "Epoch 1/10 | Iteration 1095/20187 | Loss value : 1.1329352855682373\n",
      "Epoch 1/10 | Iteration 1096/20187 | Loss value : 1.111962080001831\n",
      "Epoch 1/10 | Iteration 1097/20187 | Loss value : 1.121121883392334\n",
      "Epoch 1/10 | Iteration 1098/20187 | Loss value : 1.134057641029358\n",
      "Epoch 1/10 | Iteration 1099/20187 | Loss value : 1.0461534261703491\n",
      "Epoch 1/10 | Iteration 1100/20187 | Loss value : 1.0986034870147705\n",
      "Epoch 1/10 | Iteration 1101/20187 | Loss value : 1.1249756813049316\n",
      "Epoch 1/10 | Iteration 1102/20187 | Loss value : 1.129250407218933\n",
      "Epoch 1/10 | Iteration 1103/20187 | Loss value : 1.1574978828430176\n",
      "Epoch 1/10 | Iteration 1104/20187 | Loss value : 1.1001898050308228\n",
      "Epoch 1/10 | Iteration 1105/20187 | Loss value : 1.0904884338378906\n",
      "Epoch 1/10 | Iteration 1106/20187 | Loss value : 1.1569064855575562\n",
      "Epoch 1/10 | Iteration 1107/20187 | Loss value : 1.1185392141342163\n",
      "Epoch 1/10 | Iteration 1108/20187 | Loss value : 1.1393951177597046\n",
      "Epoch 1/10 | Iteration 1109/20187 | Loss value : 1.064650297164917\n",
      "Epoch 1/10 | Iteration 1110/20187 | Loss value : 1.108897089958191\n",
      "Epoch 1/10 | Iteration 1111/20187 | Loss value : 1.1289732456207275\n",
      "Epoch 1/10 | Iteration 1112/20187 | Loss value : 1.1007686853408813\n",
      "Epoch 1/10 | Iteration 1113/20187 | Loss value : 1.0607818365097046\n",
      "Epoch 1/10 | Iteration 1114/20187 | Loss value : 1.1254962682724\n",
      "Epoch 1/10 | Iteration 1115/20187 | Loss value : 1.088843584060669\n",
      "Epoch 1/10 | Iteration 1116/20187 | Loss value : 1.1101093292236328\n",
      "Epoch 1/10 | Iteration 1117/20187 | Loss value : 1.101527214050293\n",
      "Epoch 1/10 | Iteration 1118/20187 | Loss value : 1.111335277557373\n",
      "Epoch 1/10 | Iteration 1119/20187 | Loss value : 1.089902400970459\n",
      "Epoch 1/10 | Iteration 1120/20187 | Loss value : 1.082601547241211\n",
      "Epoch 1/10 | Iteration 1121/20187 | Loss value : 1.1024714708328247\n",
      "Epoch 1/10 | Iteration 1122/20187 | Loss value : 1.0749077796936035\n",
      "Epoch 1/10 | Iteration 1123/20187 | Loss value : 1.0953119993209839\n",
      "Epoch 1/10 | Iteration 1124/20187 | Loss value : 1.0677587985992432\n",
      "Epoch 1/10 | Iteration 1125/20187 | Loss value : 1.119164228439331\n",
      "Epoch 1/10 | Iteration 1126/20187 | Loss value : 1.1229091882705688\n",
      "Epoch 1/10 | Iteration 1127/20187 | Loss value : 1.113814353942871\n",
      "Epoch 1/10 | Iteration 1128/20187 | Loss value : 1.0779732465744019\n",
      "Epoch 1/10 | Iteration 1129/20187 | Loss value : 1.1515100002288818\n",
      "Epoch 1/10 | Iteration 1130/20187 | Loss value : 1.1066076755523682\n",
      "Epoch 1/10 | Iteration 1131/20187 | Loss value : 1.1411983966827393\n",
      "Epoch 1/10 | Iteration 1132/20187 | Loss value : 1.1356831789016724\n",
      "Epoch 1/10 | Iteration 1133/20187 | Loss value : 1.1104427576065063\n",
      "Epoch 1/10 | Iteration 1134/20187 | Loss value : 1.1258198022842407\n",
      "Epoch 1/10 | Iteration 1135/20187 | Loss value : 1.1158301830291748\n",
      "Epoch 1/10 | Iteration 1136/20187 | Loss value : 1.1006087064743042\n",
      "Epoch 1/10 | Iteration 1137/20187 | Loss value : 1.1173423528671265\n",
      "Epoch 1/10 | Iteration 1138/20187 | Loss value : 1.1261346340179443\n",
      "Epoch 1/10 | Iteration 1139/20187 | Loss value : 1.10560941696167\n",
      "Epoch 1/10 | Iteration 1140/20187 | Loss value : 1.127435564994812\n",
      "Epoch 1/10 | Iteration 1141/20187 | Loss value : 1.0867908000946045\n",
      "Epoch 1/10 | Iteration 1142/20187 | Loss value : 1.1012108325958252\n",
      "Epoch 1/10 | Iteration 1143/20187 | Loss value : 1.1088844537734985\n",
      "Epoch 1/10 | Iteration 1144/20187 | Loss value : 1.140477180480957\n",
      "Epoch 1/10 | Iteration 1145/20187 | Loss value : 1.0757538080215454\n",
      "Epoch 1/10 | Iteration 1146/20187 | Loss value : 1.1541742086410522\n",
      "Epoch 1/10 | Iteration 1147/20187 | Loss value : 1.1260908842086792\n",
      "Epoch 1/10 | Iteration 1148/20187 | Loss value : 1.1446585655212402\n",
      "Epoch 1/10 | Iteration 1149/20187 | Loss value : 1.1018166542053223\n",
      "Epoch 1/10 | Iteration 1150/20187 | Loss value : 1.1268620491027832\n",
      "Epoch 1/10 | Iteration 1151/20187 | Loss value : 1.0465807914733887\n",
      "Epoch 1/10 | Iteration 1152/20187 | Loss value : 1.1089671850204468\n",
      "Epoch 1/10 | Iteration 1153/20187 | Loss value : 1.1222633123397827\n",
      "Epoch 1/10 | Iteration 1154/20187 | Loss value : 1.133312702178955\n",
      "Epoch 1/10 | Iteration 1155/20187 | Loss value : 1.1271311044692993\n",
      "Epoch 1/10 | Iteration 1156/20187 | Loss value : 1.1066389083862305\n",
      "Epoch 1/10 | Iteration 1157/20187 | Loss value : 1.0774192810058594\n",
      "Epoch 1/10 | Iteration 1158/20187 | Loss value : 1.1081889867782593\n",
      "Epoch 1/10 | Iteration 1159/20187 | Loss value : 1.1330974102020264\n",
      "Epoch 1/10 | Iteration 1160/20187 | Loss value : 1.1438472270965576\n",
      "Epoch 1/10 | Iteration 1161/20187 | Loss value : 1.0884840488433838\n",
      "Epoch 1/10 | Iteration 1162/20187 | Loss value : 1.1022322177886963\n",
      "Epoch 1/10 | Iteration 1163/20187 | Loss value : 1.086055040359497\n",
      "Epoch 1/10 | Iteration 1164/20187 | Loss value : 1.0989500284194946\n",
      "Epoch 1/10 | Iteration 1165/20187 | Loss value : 1.1566091775894165\n",
      "Epoch 1/10 | Iteration 1166/20187 | Loss value : 1.0874515771865845\n",
      "Epoch 1/10 | Iteration 1167/20187 | Loss value : 1.0680162906646729\n",
      "Epoch 1/10 | Iteration 1168/20187 | Loss value : 1.0905989408493042\n",
      "Epoch 1/10 | Iteration 1169/20187 | Loss value : 1.1046680212020874\n",
      "Epoch 1/10 | Iteration 1170/20187 | Loss value : 1.1230034828186035\n",
      "Epoch 1/10 | Iteration 1171/20187 | Loss value : 1.1300745010375977\n",
      "Epoch 1/10 | Iteration 1172/20187 | Loss value : 1.120726466178894\n",
      "Epoch 1/10 | Iteration 1173/20187 | Loss value : 1.0944738388061523\n",
      "Epoch 1/10 | Iteration 1174/20187 | Loss value : 1.102515697479248\n",
      "Epoch 1/10 | Iteration 1175/20187 | Loss value : 1.097254753112793\n",
      "Epoch 1/10 | Iteration 1176/20187 | Loss value : 1.0923188924789429\n",
      "Epoch 1/10 | Iteration 1177/20187 | Loss value : 1.1074683666229248\n",
      "Epoch 1/10 | Iteration 1178/20187 | Loss value : 1.1466882228851318\n",
      "Epoch 1/10 | Iteration 1179/20187 | Loss value : 1.1108720302581787\n",
      "Epoch 1/10 | Iteration 1180/20187 | Loss value : 1.1209303140640259\n",
      "Epoch 1/10 | Iteration 1181/20187 | Loss value : 1.0656485557556152\n",
      "Epoch 1/10 | Iteration 1182/20187 | Loss value : 1.122991919517517\n",
      "Epoch 1/10 | Iteration 1183/20187 | Loss value : 1.0972591638565063\n",
      "Epoch 1/10 | Iteration 1184/20187 | Loss value : 1.0917984247207642\n",
      "Epoch 1/10 | Iteration 1185/20187 | Loss value : 1.1262952089309692\n",
      "Epoch 1/10 | Iteration 1186/20187 | Loss value : 1.1289374828338623\n",
      "Epoch 1/10 | Iteration 1187/20187 | Loss value : 1.0744682550430298\n",
      "Epoch 1/10 | Iteration 1188/20187 | Loss value : 1.087020993232727\n",
      "Epoch 1/10 | Iteration 1189/20187 | Loss value : 1.1070263385772705\n",
      "Epoch 1/10 | Iteration 1190/20187 | Loss value : 1.0937373638153076\n",
      "Epoch 1/10 | Iteration 1191/20187 | Loss value : 1.0691622495651245\n",
      "Epoch 1/10 | Iteration 1192/20187 | Loss value : 1.0851898193359375\n",
      "Epoch 1/10 | Iteration 1193/20187 | Loss value : 1.1265454292297363\n",
      "Epoch 1/10 | Iteration 1194/20187 | Loss value : 1.1004576683044434\n",
      "Epoch 1/10 | Iteration 1195/20187 | Loss value : 1.1419214010238647\n",
      "Epoch 1/10 | Iteration 1196/20187 | Loss value : 1.1068768501281738\n",
      "Epoch 1/10 | Iteration 1197/20187 | Loss value : 1.082903265953064\n",
      "Epoch 1/10 | Iteration 1198/20187 | Loss value : 1.1008861064910889\n",
      "Epoch 1/10 | Iteration 1199/20187 | Loss value : 1.126293659210205\n",
      "Epoch 1/10 | Iteration 1200/20187 | Loss value : 1.1002792119979858\n",
      "Epoch 1/10 | Iteration 1201/20187 | Loss value : 1.0893980264663696\n",
      "Epoch 1/10 | Iteration 1202/20187 | Loss value : 1.117101788520813\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(train_loader, transformer, criterion, epoch)\n",
    "    # state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "    # file_name = os.path.join('model_save', 'checkpoint_' + str(epoch) + '.pth.tar')\n",
    "    # torch.save(state, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
    "file_name = os.path.join('model_save', 'checkpoint_5.pth.tar')\n",
    "torch.save(transformer, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('New folder/word_map.json', 'r') as file:\n",
    "#     word_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_question(words, word_map):\n",
    "    return [word_map.get(word.lower(), word_map['<unk>']) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_text = \"i'm really worried about you , where have you been?\"\n",
    "question_tokens = question_text.lower().split()  # Simple tokenization\n",
    "encoded_question = [word_map.get(token, word_map.get(\"<unk>\")) for token in question_tokens]\n",
    "encoded_question = [token for token in encoded_question if token is not None]  # Filter out None values if <unk> is not used\n",
    "encoded_question.append(word_map['</s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_word_map = {v: k for k, v in word_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = torch.tensor([encoded_question], dtype=torch.long).to(device)  # Convert to tensor and add batch dimension\n",
    "# reply_input_mask, _ = create_masks(data, data)  # Generate mask\n",
    "# out = transformer(data, reply_input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 50  # Maximum length of the generated sentence\n",
    "end_token = word_map.get('</end>')  # Assuming you have an <end> token defined\n",
    "hoanthanh = [] \n",
    "for _ in range(max_length):\n",
    "    reply_input_mask, _ = create_masks(data, data)  # Generate mask for current input\n",
    "    out = transformer(data, reply_input_mask)  # Model prediction\n",
    "    prob = torch.softmax(out[:, -1, :], dim=-1)  # Softmax on the last token's output\n",
    "    _, next_word = torch.max(prob, dim=1)\n",
    "    next_word = next_word.item()\n",
    "\n",
    "    # Break if <end> token is predicted\n",
    "    if next_word == end_token:\n",
    "        break\n",
    "\n",
    "    # Append the predicted token to the sequence\n",
    "    data = torch.cat([data, torch.tensor([[next_word]], device=device)], dim=1)\n",
    "    hoanthanh.append(next_word)\n",
    "\n",
    "# Decoding the generated sequence\n",
    "decoded_reply = ' '.join([rev_word_map.get(idx, '<unk>') for idx in hoanthanh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You dont believe in anything ?'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4344184,
     "sourceId": 7514147,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4388279,
     "sourceId": 7540689,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
